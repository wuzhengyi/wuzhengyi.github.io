{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"\u9996\u9875"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"test/","text":"awesome-point-cloud-analysis for anyone who wants to do research about 3D point cloud. I will try to update this list everyday!!! - Recent papers (from 2017) Table of Contents 2017 2018 2019 2020 [CVPR: 70 papers; ECCV: 39 papers] Keywords dat.: dataset | cls.: classification | rel.: retrieval | seg.: segmentation det.: detection | tra.: tracking | pos.: pose | dep.: depth reg.: registration | rec.: reconstruction | aut.: autonomous driving oth.: other, including normal-related, correspondence, mapping, matching, alignment, compression, generative model... Statistics: code is available & stars >= 100 | citation >= 50 2017 [CVPR] PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. tensorflow ( https://github.com/fxia22/pointnet.pytorch )] [cls. seg. det.] [CVPR] Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs. [cls.] [CVPR] SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation. [torch] [seg. oth.] [CVPR] ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes. project ( http://www.scan-net.org/ )] [dat. cls. rel. seg. oth.] [CVPR] Scalable Surface Reconstruction from Point Clouds with Extreme Scale and Density Diversity. [oth.] [CVPR] Efficient Global Point Cloud Alignment using Bayesian Nonparametric Mixtures. [code] [oth.] [CVPR] Discriminative Optimization: Theory and Applications to Point Cloud Registration. [reg.] [CVPR] 3D Point Cloud Registration for Localization using a Deep Neural Network Auto-Encoder. [git] [reg.] [CVPR] Multi-View 3D Object Detection Network for Autonomous Driving. [tensorflow] [det. aut.] [CVPR] 3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions. [code] [dat. pos. reg. rec. oth.] [CVPR] OctNet: Learning Deep 3D Representations at High Resolutions. [torch] [cls. seg. oth.] [ICCV] Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models. [pytorch] [cls. rel. seg.] [ICCV] 3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-scale 3D Point Clouds. [code] [seg.] [ICCV] Colored Point Cloud Registration Revisited. [reg.] [ICCV] PolyFit: Polygonal Surface Reconstruction from Point Clouds. [code] [rec.] [ICCV] From Point Clouds to Mesh using Regression. [rec.] [ICCV] 3D Graph Neural Networks for RGBD Semantic Segmentation. [pytorch] [seg.] [NeurIPS] PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space. tensorflow ( https://github.com/erikwijmans/Pointnet2_PyTorch )] [cls. seg.] [NeurIPS] Deep Sets. [pytorch] [cls.] [ICRA] Vote3Deep: Fast object detection in 3D point clouds using efficient convolutional neural networks. [code] [det. aut.] [ICRA] Fast segmentation of 3D point clouds: A paradigm on LiDAR data for autonomous vehicle applications. [code] [seg. aut.] [ICRA] SegMatch: Segment based place recognition in 3D point clouds. [seg. oth.] [ICRA] Using 2 point+normal sets for fast registration of point clouds with small overlap. [reg.] [IROS] Car detection for autonomous vehicle: LIDAR and vision fusion approach through deep learning framework. [det. aut.] [IROS] 3D object classification with point convolution network. [cls.] [IROS] 3D fully convolutional network for vehicle detection in point cloud. [tensorflow] [det. aut.] [IROS] Deep learning of directional truncated signed distance function for robust 3D object recognition. [det. pos.] [IROS] Analyzing the quality of matched 3D point clouds of objects. [oth.] [3DV] SEGCloud: Semantic Segmentation of 3D Point Clouds. [project] [seg. aut.] [TPAMI] Structure-aware Data Consolidation. [oth.] 2018 [CVPR] SPLATNet: Sparse Lattice Networks for Point Cloud Processing. [caffe] [seg.] [CVPR] Attentional ShapeContextNet for Point Cloud Recognition. [cls. seg.] [CVPR] Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling. [code] [cls. seg.] [CVPR] FoldingNet: Point Cloud Auto-encoder via Deep Grid Deformation. [code] [cls.] [CVPR] Pointwise Convolutional Neural Networks. [tensorflow] [cls. seg.] [CVPR] PU-Net: Point Cloud Upsampling Network. [tensorflow] [rec. oth.] [CVPR] SO-Net: Self-Organizing Network for Point Cloud Analysis. [pytorch] [cls. seg.] [CVPR] Recurrent Slice Networks for 3D Segmentation of Point Clouds. [pytorch] [seg.] [CVPR] 3D Semantic Segmentation with Submanifold Sparse Convolutional Networks. [pytorch] [seg.] [CVPR] Deep Parametric Continuous Convolutional Neural Networks. [seg. aut.] [CVPR] PIXOR: Real-time 3D Object Detection from Point Clouds. [pytorch] [det. aut.] [CVPR] SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation. [tensorflow] [seg.] [CVPR] Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs. [pytorch] [seg.] [CVPR] VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection. [tensorflow] [det. aut.] [CVPR] Reflection Removal for Large-Scale 3D Point Clouds. [oth.] [CVPR] Hand PointNet: 3D Hand Pose Estimation using Point Sets. [pytorch] [pos.] [CVPR] PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition. [tensorflow] [rel.] [CVPR] A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation. [cls.] [CVPR] Density Adaptive Point Set Registration. [code] [reg.] [CVPR] A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds. [seg.] [CVPR] Inverse Composition Discriminative Optimization for Point Cloud Registration. [reg.] [CVPR] CarFusion: Combining Point Tracking and Part Detection for Dynamic 3D Reconstruction of Vehicles. [tra. det. rec.] [CVPR] PPFNet: Global Context Aware Local Features for Robust 3D Point Matching. [oth.] [CVPR] PointGrid: A Deep Network for 3D Shape Understanding. [tensorflow] [cls. seg.] [CVPR] PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation. [code] [det. aut.] [CVPR] Frustum PointNets for 3D Object Detection from RGB-D Data. [tensorflow] [det. aut.] [CVPR] Tangent Convolutions for Dense Prediction in 3D. [tensorflow] [seg. aut.] [ECCV] Multiresolution Tree Networks for 3D Point Cloud Processing. [pytorch] [cls.] [ECCV] EC-Net: an Edge-aware Point set Consolidation Network. [tensorflow] [oth.] [ECCV] 3D Recurrent Neural Networks with Context Fusion for Point Cloud Semantic Segmentation. [seg.] [ECCV] Learning and Matching Multi-View Descriptors for Registration of Point Clouds. [reg.] [ECCV] 3DFeat-Net: Weakly Supervised Local 3D Features for Point Cloud Registration. [tensorflow] [reg.] [ECCV] Local Spectral Graph Convolution for Point Set Feature Learning. [tensorflow] [cls. seg.] [ECCV] SpiderCNN: Deep Learning on Point Sets with Parameterized Convolutional Filters. [tensorflow] [cls. seg.] [ECCV] Efficient Global Point Cloud Registration by Matching Rotation Invariant Features Through Translation Search. [reg.] [ECCV] Efficient Dense Point Cloud Object Reconstruction using Deformation Vector Fields. [rec.] [ECCV] Fully-Convolutional Point Networks for Large-Scale Point Clouds. [tensorflow] [seg. oth.] [ECCV] Deep Continuous Fusion for Multi-Sensor 3D Object Detection. [det.] [ECCV] HGMR: Hierarchical Gaussian Mixtures for Adaptive 3D Registration. [reg.] [ECCV] Point-to-Point Regression PointNet for 3D Hand Pose Estimation. [pos.] [ECCV] PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors. [oth.] [ECCVW] 3DContextNet: K-d Tree Guided Hierarchical Learning of Point Clouds Using Local and Global Contextual Cues. [cls. seg.] [ECCVW] YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection from LiDAR Point Cloud. [det. aut.] [AAAI] Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction. [tensorflow] [rec.] [AAAI] Adaptive Graph Convolutional Neural Networks. [cls.] [NeurIPS] Unsupervised Learning of Shape and Pose with Differentiable Point Clouds. [tensorflow] [pos.] [NeurIPS] PointCNN: Convolution On X-Transformed Points. tensorflow ( https://github.com/hxdengBerkeley/PointCNN.Pytorch )] [cls. seg.] [ICML] Learning Representations and Generative Models for 3D Point Clouds. [code] [oth.] [TOG] Point Convolutional Neural Networks by Extension Operators. [tensorflow] [cls. seg.] [SIGGRAPH] P2P-NET: Bidirectional Point Displacement Net for Shape Transform. [tensorflow] [oth.] [SIGGRAPH Asia] Monte Carlo Convolution for Learning on Non-Uniformly Sampled Point Clouds. [tensorflow] [cls. seg. oth.] [SIGGRAPH] Learning local shape descriptors from part correspondences with multi-view convolutional networks. [project] [seg. oth.] [MM] PVNet: A Joint Convolutional Network of Point Cloud and Multi-View for 3D Shape Recognition. [cls. rel.] [MM] RGCNN: Regularized Graph CNN for Point Cloud Segmentation. [tensorflow] [seg.] [MM] Hybrid Point Cloud Attribute Compression Using Slice-based Layered Structure and Block-based Intra Prediction. [oth.] [ICRA] End-to-end Learning of Multi-sensor 3D Tracking by Detection. [det. tra. aut.] [ICRA] Multi-View 3D Entangled Forest for Semantic Segmentation and Mapping. [seg. oth.] [ICRA] SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud. [tensorflow] [seg. aut.] [ICRA] Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications. [det.] [ICRA] High-Precision Depth Estimation with the 3D LiDAR and Stereo Fusion. [dep. aut.] [ICRA] Sampled-Point Network for Classification of Deformed Building Element Point Clouds. [cls.] [ICRA] Gemsketch: Interactive Image-Guided Geometry Extraction from Point Clouds. [oth.] [ICRA] Signature of Topologically Persistent Points for 3D Point Cloud Description. [oth.] [ICRA] A General Pipeline for 3D Detection of Vehicles. [det. aut.] [ICRA] Robust and Fast 3D Scan Alignment Using Mutual Information. [oth.] [ICRA] Delight: An Efficient Descriptor for Global Localisation Using LiDAR Intensities. [oth.] [ICRA] Surface-Based Exploration for Autonomous 3D Modeling. [oth. aut.] [ICRA] Deep Lidar CNN to Understand the Dynamics of Moving Vehicles. [oth. aut.] [ICRA] Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning. [oth.] [ICRA] Real-Time Object Tracking in Sparse Point Clouds Based on 3D Interpolation. [tra.] [ICRA] Robust Generalized Point Cloud Registration Using Hybrid Mixture Model. [reg.] [ICRA] A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration. [reg.] [ICRA] Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping. [oth.] [ICRA] Direct Visual SLAM Using Sparse Depth for Camera-LiDAR System. [oth.] [ICRA] Spatiotemporal Learning of Dynamic Gestures from 3D Point Cloud Data. [cls.] [ICRA] Asynchronous Multi-Sensor Fusion for 3D Mapping and Localization. [oth.] [ICRA] Complex Urban LiDAR Data Set. [video] [dat. oth.] [IROS] CalibNet: Geometrically Supervised Extrinsic Calibration using 3D Spatial Transformer Networks.[tensorflow] [oth. aut.] [IROS] Dynamic Scaling Factors of Covariances for Accurate 3D Normal Distributions Transform Registration. [reg.] [IROS] A 3D Laparoscopic Imaging System Based on Stereo-Photogrammetry with Random Patterns. [rec. oth.] [IROS] Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties. [reg.] [IROS] Octree map based on sparse point cloud and heuristic probability distribution for labeled images. [oth. aut.] [IROS] PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization. [oth.] [IROS] Scan Context: Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map. [oth.] [IROS] LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain.[code] [pos. oth.] [IROS] Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds. [cls.] [IROS] Stereo Camera Localization in 3D LiDAR Maps. [pos. oth.] [IROS] Joint 3D Proposal Generation and Object Detection from View Aggregation. [det.] [IROS] Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality. [oth.] [IROS] Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding. [det. oth.] [IROS] NDVI Point Cloud Generator Tool Using Low-Cost RGB-D Sensor. code [IROS] A 3D Convolutional Neural Network Towards Real-Time Amodal 3D Object Detection. [det. pos.] [IROS] Extracting Phenotypic Characteristics of Corn Crops Through the Use of Reconstructed 3D Models. [seg. rec.] [IROS] PCAOT: A Manhattan Point Cloud Registration Method Towards Large Rotation and Small Overlap. [reg.] [IROS] [Tensorflow]3DmFV: Point Cloud Classification and segmentation for unstructured 3D point clouds. [cls. ] [IROS] Seeing the Wood for the Trees: Reliable Localization in Urban and Natural Environments. [oth. ] [SENSORS] SECOND: Sparsely Embedded Convolutional Detection. [pytorch] [det. aut.] [ACCV] Flex-Convolution (Million-Scale Point-Cloud Learning Beyond Grid-Worlds). [tensorflow] [seg.] [3DV] PCN: Point Completion Network. [tensorflow] [reg. oth. aut.] [ICASSP] A Graph-CNN for 3D Point Cloud Classification. [tensorflow] [cls.] [ITSC] BirdNet: a 3D Object Detection Framework from LiDAR information. [det. aut.] [arXiv] PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation. [tensorflow] [seg.] [arXiv] Spherical Convolutional Neural Network for 3D Point Clouds. [cls.] [arXiv] Adversarial Autoencoders for Generating 3D Point Clouds. [oth.] [arXiv] Iterative Transformer Network for 3D Point Cloud. [cls. seg. pos.] [arXiv] Topology-Aware Surface Reconstruction for Point Clouds. [rec.] [arXiv] Inferring Point Clouds from Single Monocular Images by Depth Intermediation. [oth.] [arXiv] Deep RBFNet: Point Cloud Feature Learning using Radial Basis Functions. [cls.] [arXiv] IPOD: Intensive Point-based Object Detector for Point Cloud. [det.] [arXiv] Feature Preserving and Uniformity-controllable Point Cloud Simplification on Graph. [oth.] [arXiv] POINTCLEANNET: Learning to Denoise and Remove Outliers from Dense Point Clouds. [pytorch] [oth.] [arXiv] Complex-YOLO: Real-time 3D Object Detection on Point Clouds. [pytorch] [det. aut.] [arxiv] RoarNet: A Robust 3D Object Detection based on RegiOn Approximation Refinement. [tensorflow] [det. aut.] [arXiv] Multi-column Point-CNN for Sketch Segmentation. [seg.] [arXiv] PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention. [project] [oth.] [arXiv] Point Cloud GAN. [pytorch] [oth.] 2019 [CVPR] Relation-Shape Convolutional Neural Network for Point Cloud Analysis. [pytorch] [cls. seg. oth.] [CVPR] Spherical Fractal Convolutional Neural Networks for Point Cloud Recognition. [cls. seg.] [CVPR] DeepMapping: Unsupervised Map Estimation From Multiple Point Clouds. [code] [reg.] [CVPR] Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving. [code] [det. dep. aut.] [CVPR] PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud. [pytorch] [det. aut.] [CVPR] Generating 3D Adversarial Point Clouds. [code] [oth.] [CVPR] Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling. [cls. seg.] [CVPR] A-CNN: Annularly Convolutional Neural Networks on Point Clouds. tensorflow [CVPR] PointConv: Deep Convolutional Networks on 3D Point Clouds. [tensorflow] [cls. seg.] [CVPR] Path-Invariant Map Networks. [tensorflow] [seg. oth.] [CVPR] PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding. [code] [dat. seg.] [CVPR] GeoNet: Deep Geodesic Networks for Point Cloud Analysis. [cls. rec. oth.] [CVPR] Associatively Segmenting Instances and Semantics in Point Clouds. [tensorflow] [seg.] [CVPR] Supervised Fitting of Geometric Primitives to 3D Point Clouds. [tensorflow] [oth.] [CVPR] Octree guided CNN with Spherical Kernels for 3D Point Clouds. [extension] [code] [cls. seg.] [CVPR] PointNetLK: Point Cloud Registration using PointNet. [pytorch] [reg.] [CVPR] JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds with Multi-Task Pointwise Networks and Multi-Value Conditional Random Fields. [pytorch] [seg.] [CVPR] Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning. [seg.] [CVPR] PointPillars: Fast Encoders for Object Detection from Point Clouds. [pytorch] [det.] [CVPR] Patch-based Progressive 3D Point Set Upsampling. [tensorflow] [oth.] [CVPR] PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval. [code] [rel.] [CVPR] PartNet: A Recursive Part Decomposition Network for Fine-grained and Hierarchical Shape Segmentation. [pytorch] [dat. seg.] [CVPR] PointFlowNet: Learning Representations for Rigid Motion Estimation from Point Clouds. [code] [det. dat. oth.] [CVPR] SDRSAC: Semidefinite-Based Randomized Approach for Robust Point Cloud Registration without Correspondences. [matlab] [reg.] [CVPR] Deep Reinforcement Learning of Volume-guided Progressive View Inpainting for 3D Point Scene Completion from a Single Depth Image. [rec. oth.] [CVPR] Embodied Question Answering in Photorealistic Environments with Point Cloud Perception. [oth.] [CVPR] 3D Point-Capsule Networks. [pytorch] [cls. rec. oth.] [CVPR] 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks. [pytorch] [seg.] [CVPR] The Perfect Match: 3D Point Cloud Matching with Smoothed Densities. [tensorflow] [oth.] [CVPR] FilterReg: Robust and Efficient Probabilistic Point-Set Registration using Gaussian Filter and Twist Parameterization. [code] [reg.] [CVPR] FlowNet3D: Learning Scene Flow in 3D Point Clouds. [oth.] [CVPR] Modeling Local Geometric Structure of 3D Point Clouds using Geo-CNN. [cls. det.] [CVPR] ClusterNet: Deep Hierarchical Cluster Network with Rigorously Rotation-Invariant Representation for Point Cloud Analysis. [cls.] [CVPR] PointWeb: Enhancing Local Neighborhood Features for Point Cloud Processing. [pytorch] [cls. seg.] [CVPR] RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion. [code] [oth.] [CVPR] PointNetLK: Robust & Efficient Point Cloud Registration using PointNet. [pytorch] [reg.] [CVPR] Robust Point Cloud Based Reconstruction of Large-Scale Outdoor Scenes. [code] [rec.] [CVPR] Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds using Convolutional Neural Networks. [tensorflow] [oth.] [CVPR] GSPN: Generative Shape Proposal Network for 3D Instance Segmentation in Point Cloud. [seg.] [CVPR] Graph Attention Convolution for Point Cloud Semantic Segmentation. [seg.] [CVPR] Point-to-Pose Voting based Hand Pose Estimation using Residual Permutation Equivariant Layer. [pos.] [CVPR] LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving. [det. aut.] [CVPR] LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks. [project] [cls. seg.] [CVPR] Structural Relational Reasoning of Point Clouds. [cls. seg.] [CVPR] 3DN: 3D Deformation Network. [tensorflow] [rec. oth.] [CVPR] Privacy Preserving Image-Based Localization. [pos. oth.] [CVPR] Argoverse: 3D Tracking and Forecasting With Rich Maps.[tra. aut.] [CVPR] Leveraging Shape Completion for 3D Siamese Tracking. [pytorch] [tra. ] [CVPRW] Attentional PointNet for 3D-Object Detection in Point Clouds. [pytorch] [cls. det. aut.] [CVPR] 3D Local Features for Direct Pairwise Registration. [reg.] [CVPR] Learning to Sample. [tensorflow] [cls. rec.] [CVPR] Revealing Scenes by Inverting Structure from Motion Reconstructions. [code] [rec.] [CVPR] DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene from Sparse LiDAR Data and Single Color Image. [pytorch] [dep.] [CVPR] HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-scale Point Clouds. [pytorch] [oth.] \u00b6 [ICCV] Deep Hough Voting for 3D Object Detection in Point Clouds. [pytorch] [tensorflow] [det.] [ICCV] DeepGCNs: Can GCNs Go as Deep as CNNs? [tensorflow] [pytorch] [seg.] [ICCV] PU-GAN: a Point Cloud Upsampling Adversarial Network. [tensorflow] [oth.] [ICCV] 3D Point Cloud Learning for Large-scale Environment Analysis and Place Recognition. [rel. oth.] [ICCV] PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows. [pytorch] [oth.] [ICCV] Multi-Angle Point Cloud-VAE: Unsupervised Feature Learning for 3D Point Clouds from Multiple Angles by Joint Self-Reconstruction and Half-to-Half Prediction. [oth.] [ICCV] SO-HandNet: Self-Organizing Network for 3D Hand Pose Estimation with Semi-supervised Learning. [code] [pos.] [ICCV] DUP-Net: Denoiser and Upsampler Network for 3D Adversarial Point Clouds Defense. [oth.] [ICCV] Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data. [cls. dat.] [code] [dataset] [ICCV] KPConv: Flexible and Deformable Convolution for Point Clouds. [tensorflow] [cls. seg.] [ICCV] ShellNet: Efficient Point Cloud Convolutional Neural Networks using Concentric Shells Statistics. [project] [seg.] [ICCV] Point-Based Multi-View Stereo Network. [pytorch] [rec.] [ICCV] DensePoint: Learning Densely Contextual Representation for Efficient Point Cloud Processing. [pytorch] [cls. seg. oth.] [ICCV] DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration. [reg.] [ICCV] 3D Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions. [pytorch] [oth.] [ICCV] Hierarchical Point-Edge Interaction Network for Point Cloud Semantic Segmentation. [seg.] [ICCV] Learning an Effective Equivariant 3D Descriptor Without Supervision. [oth.] [ICCV] Fully Convolutional Geometric Features. [pytorch] [reg.] [ICCV] LPD-Net: 3D Point Cloud Learning for Large-Scale Place Recognition and Environment Analysis. [oth. aut.] [ICCV] Total Denoising: Unsupervised Learning of 3D Point Cloud Cleaning. [tensorflow] [oth.] [ICCV] USIP: Unsupervised Stable Interest Point Detection from 3D Point Clouds. [pytorch] [oth.] [ICCV] Interpolated Convolutional Networks for 3D Point Cloud Understanding. [cls. seg.] [ICCV] PointCloud Saliency Maps. [code] [oth.] [ICCV] STD: Sparse-to-Dense 3D Object Detector for Point Cloud. [det. oth.] [ICCV] Accelerated Gravitational Point Set Alignment with Altered Physical Laws. [reg.] [ICCV] Deep Closest Point: Learning Representations for Point Cloud Registration. [reg.] [ICCV] Efficient Learning on Point Clouds with Basis Point Sets. [code] [cls. reg.] [ICCV] PointAE: Point Auto-encoder for 3D Statistical Shape and Texture Modelling. [rec.] [ICCV] Skeleton-Aware 3D Human Shape Reconstruction From Point Clouds. [rec.] [ICCV] Dynamic Points Agglomeration for Hierarchical Point Sets Learning. [pytorch] [cls. seg.] [ICCV] Unsupervised Multi-Task Feature Learning on Point Clouds. [cls. seg.] [ICCV] VV-NET: Voxel VAE Net with Group Convolutions for Point Cloud Segmentation. [tensorflow] [seg.] [ICCV] GraphX-Convolution for Point Cloud Deformation in 2D-to-3D Conversion. [pytorch] [rec.] [ICCV] MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences. [code] [cls. seg. oth.] [ICCV] Fast Point R-CNN. [det. aut.] [ICCV] Robust Variational Bayesian Point Set Registration. [reg.] [ICCV] DiscoNet: Shapes Learning on Disconnected Manifolds for 3D Editing. [rec. oth.] [ICCV] Learning an Effective Equivariant 3D Descriptor Without Supervision. [oth.] [ICCV] 3D Instance Segmentation via Multi-Task Metric Learning. [code] [seg.] [ICCV] 3D Face Modeling From Diverse Raw Scan Data. [rec.] [ICCVW] Range Adaptation for 3D Object Detection in LiDAR. [det. aut.] \u00b6 [NeurIPS] Self-Supervised Deep Learning on Point Clouds by Reconstructing Space. [cls. oth.] [NeurIPS] Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds. [tensorflow] [det. seg.] [NeurIPS] Exploiting Local and Global Structure for Point Cloud Semantic Segmentation with Contextual Point Representations. [tensorflow] [seg.] [NeurIPS] Point-Voxel CNN for Efficient 3D Deep Learning. [det. seg. aut.] [NeurIPS] PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation. [code] [cls. oth.] \u00b6 [ICLR] Learning Localized Generative Models for 3D Point Clouds via Graph Convolution. [oth.] \u00b6 [ICMLW] LiDAR Sensor modeling and Data augmentation with GANs for Autonomous driving. [det. oth. aut.] \u00b6 [AAAI] CAPNet: Continuous Approximation Projection For 3D Point Cloud Reconstruction Using 2D Supervision. [code] [rec.] [AAAI] Point2Sequence: Learning the Shape Representation of 3D Point Clouds with an Attention-based Sequence to Sequence Network. [tensorflow] [cls. seg.] [AAAI] Point Cloud Processing via Recurrent Set Encoding. [cls.] [AAAI] PVRNet: Point-View Relation Neural Network for 3D Shape Recognition. [pytorch] [cls. rel.] [AAAI] Hypergraph Neural Networks. [pytorch] [cls.] \u00b6 [TOG] Dynamic Graph CNN for Learning on Point Clouds. tensorflow ( https://github.com/WangYueFt/dgcnn )] [cls. seg.] [TOG] LOGAN: Unpaired Shape Transform in Latent Overcomplete Space. [tensorflow] [oth.] [SIGGRAPH Asia] StructureNet: Hierarchical Graph Networks for 3D Shape Generation. [seg. oth.] \u00b6 [MM] MMJN: Multi-Modal Joint Networks for 3D Shape Recognition. [cls. rel.] [MM] 3D Point Cloud Geometry Compression on Deep Learning. [oth.] [MM] SRINet: Learning Strictly Rotation-Invariant Representations for Point Cloud Classification and Segmentation. [tensorflow] [cls. seg.] [MM] L2G Auto-encoder: Understanding Point Clouds by Local-to-Global Reconstruction with Hierarchical Self-Attention. [cls. rel.] [MM] Ground-Aware Point Cloud Semantic Segmentation for Autonomous Driving. [code] [seg. aut.] \u00b6 [ICME] Justlookup: One Millisecond Deep Feature Extraction for Point Clouds By Lookup Tables. [cls. rel.] \u00b6 [ICASSP] 3D Point Cloud Denoising via Deep Neural Network based Local Surface Estimation. [code] [oth.] \u00b6 [BMVC] Mitigating the Hubness Problem for Zero-Shot Learning of 3D Objects. [cls.] \u00b6 [ICRA] Discrete Rotation Equivariance for Point Cloud Recognition. [pytorch] [cls.] [ICRA] SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud. [tensorflow] [seg. aut.] [ICRA] Detection and Tracking of Small Objects in Sparse 3D Laser Range Data. [det. tra. aut.] [ICRA] Oriented Point Sampling for Plane Detection in Unorganized Point Clouds. [det. seg.] [ICRA] Point Cloud Compression for 3D LiDAR Sensor Using Recurrent Neural Network with Residual Blocks. [pytorch] [oth.] [ICRA] Focal Loss in 3D Object Detection. [code] [det. aut.] [ICRA] PointNetGPD: Detecting Grasp Configurations from Point Sets. [pytorch] [det. seg.] [ICRA] 2D3D-MatchNet: Learning to Match Keypoints across 2D Image and 3D Point Cloud. [oth.] [ICRA] Speeding up Iterative Closest Point Using Stochastic Gradient Descent. [oth.] [ICRA] Uncertainty Estimation for Projecting Lidar Points Onto Camera Images for Moving Platforms. [oth.] [ICRA] SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data. [det. aut.] [ICRA] BLVD: Building A Large-scale 5D Semantics Benchmark for Autonomous Driving. [project] [dat. det. tra. aut. oth.] [ICRA] A Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications. [det.] [ICRA] Robust low-overlap 3-D point cloud registration for outlier rejection. [matlab] [reg.] [ICRA] Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution. [cls. seg.] [ICRA] Hierarchical Depthwise Graph Convolutional Neural Network for 3D Semantic Segmentation of Point Clouds. [seg.] [ICRA] Robust Generalized Point Set Registration Using Inhomogeneous Hybrid Mixture Models Via Expectation. [reg.] [ICRA] Dense 3D Visual Mapping via Semantic Simplification. [oth.] [ICRA] MVX-Net: Multimodal VoxelNet for 3D Object Detection. [det. aut.] [ICRA] CELLO-3D: Estimating the Covariance of ICP in the Real World. [reg.] \u00b6 [IROS] EPN: Edge-Aware PointNet for Object Recognition from Multi-View 2.5D Point Clouds. [tensorflow] [cls. det.] [IROS] SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles. [oth.] [aut.] [IROS] PASS3D: Precise and Accelerated Semantic Segmentation for 3D Point Cloud. [seg. aut.] \u00b6 [IV] End-to-End 3D-PointCloud Semantic Segmentation for Autonomous Driving. [seg.] [aut.] \u00b6 [Eurographics Workshop] Generalizing Discrete Convolutions for Unstructured Point Clouds. [pytorch] [cls. seg.] \u00b6 [WACV] 3DCapsule: Extending the Capsule Architecture to Classify 3D Point Clouds. [cls.] \u00b6 [3DV] Rotation Invariant Convolutions for 3D Point Clouds Deep Learning. [project] [cls. seg.] [3DV] Effective Rotation-invariant Point CNN with Spherical Harmonics kernels. [tensorflow] [cls. seg. oth.] \u00b6 [TVCG] LassoNet: Deep Lasso-Selection of 3D Point Clouds. [project] [oth.] \u00b6 [arXiv] Fast 3D Line Segment Detection From Unorganized Point Cloud. [det.] [arXiv] Point-Cloud Saliency Maps. [tensorflow] [cls. oth.] [arXiv] Extending Adversarial Attacks and Defenses to Deep 3D Point Cloud Classifiers. [code] [oth.] [arxiv] Context Prediction for Unsupervised Deep Learning on Point Clouds. [cls. seg.] [arXiv] Points2Pix: 3D Point-Cloud to Image Translation using conditional Generative Adversarial Networks. [oth.] [arXiv] NeuralSampler: Euclidean Point Cloud Auto-Encoder and Sampler. [cls. oth.] [arXiv] 3D Graph Embedding Learning with a Structure-aware Loss Function for Point Cloud Semantic Instance Segmentation. [seg.] [arXiv] Zero-shot Learning of 3D Point Cloud Objects. [code] [cls.] [arXiv] Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud. [det. aut.] [arXiv] Real-time Multiple People Hand Localization in 4D Point Clouds. [det. oth.] [arXiv] Variational Graph Methods for Efficient Point Cloud Sparsification. [oth.] [arXiv] Neural Style Transfer for Point Clouds. [oth.] [arXiv] OREOS: Oriented Recognition of 3D Point Clouds in Outdoor Scenarios. [pos. oth.] [arXiv] FVNet: 3D Front-View Proposal Generation for Real-Time Object Detection from Point Clouds. [code] [det. aut.] [arXiv] Unpaired Point Cloud Completion on Real Scans using Adversarial Training. [oth.] [arXiv] MortonNet: Self-Supervised Learning of Local Features in 3D Point Clouds. [cls. seg.] [arXiv] DeepPoint3D: Learning Discriminative Local Descriptors using Deep Metric Learning on 3D Point Clouds. [cls. rel. oth.] [arXiv] Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds. [pytorch] [det. tra. aut.] [arXiv] Graph-based Inpainting for 3D Dynamic Point Clouds. [oth.] [arXiv] nuScenes: A multimodal dataset for autonomous driving. [link] [dat. det. tra. aut.] [arXiv] 3D Backbone Network for 3D Object Detection. [code] [det. aut.] [arXiv] Adversarial Autoencoders for Compact Representations of 3D Point Clouds. [pytorch] [rel. oth.] [arXiv] Linked Dynamic Graph CNN: Learning on Point Cloud via Linking Hierarchical Features. [cls. seg.] [arXiv] GAPNet: Graph Attention based Point Neural Network for Exploiting Local Feature of Point Cloud. [tensorflow] [cls. seg.] [arXiv] Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds. [tensorflow] [det. seg.] [arXiv] Differentiable Surface Splatting for Point-based Geometry Processing. [pytorch] [oth.] [arXiv] Spatial Transformer for 3D Points. [seg.] [arXiv] Point-Voxel CNN for Efficient 3D Deep Learning. [seg. det. aut.] [arXiv] Attentive Context Normalization for Robust Permutation-Equivariant Learning. [cls.] [arXiv] Neural Point-Based Graphics. [project] [oth.] [arXiv] Point Cloud Super Resolution with Adversarial Residual Graph Networks. [oth.] [tensorflow] [arXiv] Blended Convolution and Synthesis for Efficient Discrimination of 3D Shapes. [cls. rel.] [arXiv] StarNet: Targeted Computation for Object Detection in Point Clouds. [tensorflow] [det.] [arXiv] Efficient Tracking Proposals using 2D-3D Siamese Networks on LIDAR. [tra.] [arXiv] SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing. [tensorflow] [cls. seg.] [arXiv] Part-A^2 Net: 3D Part-Aware and Aggregation Neural Network for Object Detection from Point Cloud. [det. aut.] [arXiv] PyramNet: Point Cloud Pyramid Attention Network and Graph Embedding Module for Classification and Segmentation. [cls. seg.] [arXiv] PointRNN: Point Recurrent Neural Network for Moving Point Cloud Processing. [tensorflow] [tra. oth. aut.] [arXiv] PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points. [tensorflow] [cls. seg.] [arXiv] Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds. [oth.] [arXiv] 3D-Rotation-Equivariant Quaternion Neural Networks. [cls. rec.] [arXiv] Point2SpatialCapsule: Aggregating Features and Spatial Relationships of Local Regions on Point Clouds using Spatial-aware Capsules. [cls. rel. seg.] [arXiv] Geometric Feedback Network for Point Cloud Classification. [cls.] [arXiv] Relation Graph Network for 3D Object Detection in Point Clouds. [det.] [arXiv] Deformable Filter Convolution for Point Cloud Reasoning. [seg. det. aut.] [arXiv] PU-GCN: Point Cloud Upsampling via Graph Convolutional Network. [project] [oth.] [arXiv] Grid-GCN for Fast and Scalable Point Cloud Learning. [seg. cls.] [arXiv] PointPainting: Sequential Fusion for 3D Object Detection. [seg. det.] [arXiv] Transductive Zero-Shot Learning for 3D Point Cloud Classification. [cls.] [arXiv] Geometry Sharing Network for 3D Point Cloud Classification and Segmentation. [pytorch] [cls. seg.] [arvix] Deep Learning for 3D Point Clouds: A Survey. [code] [cls. det. tra. seg.] [arXiv] Spectral-GANs for High-Resolution 3D Point-cloud Generation. [rec. oth.] [arXiv] Point Attention Network for Semantic Segmentation of 3D Point Clouds. [seg.] [arXiv] PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation. [oth.] [arXiv] 3D Object Recognition with Ensemble Learning --- A Study of Point Cloud-Based Deep Learning Models. [cls. det.] 2020 [AAAI] Morphing and Sampling Network for Dense Point Cloud Completion. [pytorch] [oth.] [AAAI] TANet: Robust 3D Object Detection from Point Clouds with Triple Attention. [code] [det. aut.] [AAAI] Point2Node: Correlation Learning of Dynamic-Node for Point Cloud Feature Modeling. [seg. cls.] [AAAI] PRIN: Pointwise Rotation-Invariant Network. [seg. cls.] [AAAI] SK-Net: Deep Learning on Point Cloud via End-to-end Discovery of Spatial Keypoints. [oth] [AAAI] JSNet: Joint Instance and Semantic Segmentation of 3D Point Clouds. tensorflow [AAAI] ZoomNet: Part-Aware Adaptive Zooming Neural Network for 3D Object Detection. [det.] [AAAI] Shape-Oriented Convolution Neural Network for Point Cloud Analysis. [cls.] \u00b6 [CVPR] RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds. [tensorflow] [seg.] [CVPR] Learning multiview 3D point cloud registration. [code] [reg.] [CVPR] PF-Net: Point Fractal Network for 3D Point Cloud Completion. [pytorch] [oth.] [CVPR] ImVoteNet: Boosting 3D Object Detection in Point Clouds with Image Votes. [det.] [CVPR] Fusion-Aware Point Convolution for Online Semantic 3D Scene Segmentation. [pytorch] [seg.] [CVPR] AdaCoSeg: Adaptive Shape Co-Segmentation with Group Consistency Loss. [seg.] [CVPR] SA-SSD: Structure Aware Single-Stage 3D Object Detection from Point Cloud. [pytorch] [det.] [CVPR] PointAugment: an Auto-Augmentation Framework for Point Cloud Classification. [code] [classification.] [CVPR] Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud. tensorflow [CVPR] Multi-Path Region Mining For Weakly Supervised 3D Semantic Segmentation on Point Clouds. [seg.] [CVPR] Global-Local Bidirectional Reasoning for Unsupervised Representation Learning of 3D Point Clouds. pytorch [CVPR] PointGMM: a Neural GMM Network for Point Clouds. code [CVPR] RPM-Net: Robust Point Matching using Learned Features. [code] [seg.] [CVPR] Unsupervised Learning of Intrinsic Structural Representation Points. pytorch [CVPR] PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation. [pytorch] [seg.] [CVPR] 3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation. [seg.] [CVPR] DOPS: Learning to Detect 3D Objects and Predict their 3D Shapes. [det.] [CVPR] OccuSeg: Occupancy-aware 3D Instance Segmentation. [seg.] [CVPR] MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird's Eye View Maps. [oth.] [CVPR] Learning to Segment 3D Point Clouds in 2D Image Space. [pytorch] [seg] [CVPR] D3Feat: Joint Learning of Dense Detection and Description of 3D Local Features. [cls] [CVPR] PointASNL: Robust Point Clouds Processing using Nonlocal Neural Networks with Adaptive Sampling. [cls.] [CVPR] Physically Realizable Adversarial Examples for LiDAR Object Detection. [det.] [CVPR] HVNet: Hybrid Voxel Network for LiDAR Based 3D Object Detection. [det] [CVPR] LiDAR-based Online 3D Video Object Detection with Graph-based Message Passing and Spatiotemporal Transformer Attention. code [CVPR] PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation. [seg.] [CVPR] DualSDF: Semantic Shape Manipulation using a Two-Level Representation. code [CVPR] Disp R-CNN: Stereo 3D Object Detection via Shape Prior Guided Instance Disparity Estimation. pytorch [CVPR] End-to-End Pseudo-LiDAR for Image-Based 3D Object Detection. [code] [det.] [CVPR] Cascaded Refinement Network for Point Cloud Completion. code [CVPR] MLCVNet: Multi-Level Context VoteNet for 3D Object Detection. code [CVPR] Learning 3D Semantic Scene Graphs from 3D Indoor Reconstructions. [oth.] [CVPR] Joint Spatial-Temporal Optimization for Stereo 3D Object Tracking. [track.] [CVPR] StructEdit: Learning Structural Shape Variations. [project] [rec.] [CVPR] Connect-and-Slice: an hybrid approach for reconstructing 3D objects. [reconstruction.] [CVPR] SGAS: Sequential Greedy Architecture Search. [pytorch] ['cls.'] [CVPR oral] Deep Global Registration. ['reg.'] [CVPR] 3DSSD: Point-based 3D Single Stage Object Detector. [det] [CVPR] Going Deeper with Point Networks. pytorch [CVPR] Connect-and-Slice: an hybrid approach for reconstructing 3D objects. [reconstruction] [CVPR] Feature-metric Registration: A Fast Semi-supervised Approach for Robust Point Cloud Registration without Correspondences. [registration] [CVPR] From Image Collections to Point Clouds with Self-supervised Shape and Pose Networks. tensorflow [CVPR] PointPainting: Sequential Fusion for 3D Object Detection. [detection] [CVPR] xMUDA: Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation. [Segmentation] [CVPR] FroDO: From Detections to 3D Objects. [detection] [CVPR oral] OctSqueeze: Octree-Structured Entropy Model for LiDAR Compression. [Compression] [CVPR] Train in Germany, Test in The USA: Making 3D Object Detectors Generalize. code [CVPR oral] High-dimensional Convolutional Networks for Geometric Pattern Recognition. code [CVPR oral] P2B: Point-to-Box Network for 3D Object Tracking in Point Clouds. pytorch [CVPR] Associate-3Ddet: Perceptual-to-Conceptual Association for 3D Point Cloud Object Detection. [detection] [CVPR] RevealNet: Seeing Behind Objects in RGB-D Scans. [Completion] [CVPR] A Hierarchical Graph Network for 3D Object Detection on Point Clouds. [Detection] [CVPR] Density Based Clustering for 3D Object Detection in Point Clouds. [Detection] [CVPR] Joint 3D Instance Segmentation and Object Detection for Autonomous Driving. [Detection] [CVPR] Neural Implicit Embedding for Point Cloud Analysis. [Analysis] [CVPR] End-to-End 3D Point Cloud Instance Segmentation Without Detection. [Segmentation] [CVPR] Adaptive Hierarchical Down-Sampling for Point Cloud Classification. [Classification] [CVPR] Geometry and Learning Co-Supported Normal Estimation for Unstructured Point Cloud. [Normal] [CVPR] Weakly Supervised Semantic Point Cloud Segmentation: Towards 10x Fewer Labels. [Segmentation] [CVPR] SegGCN: Efficient 3D Point Cloud Segmentation With Fuzzy Spherical Kernel. [Segmentation] [CVPR] LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud Based Deep Networks. [Attack] [CVPR] SampleNet: Differentiable Point Cloud Sampling. [Sampling] [CVPR] Sequential 3D Human Pose and Shape Estimation From Point Clouds. [Pose] [CVPR] An Efficient PointLSTM for Point Clouds Based Gesture Recognition. [Recognition] [CVPR] Grid-GCN for Fast and Scalable Point Cloud Learning. [other] [CVPR] SpSequenceNet: Semantic Segmentation Network on 4D Point Clouds. [Segmentation] [CVPR] Point Cloud Completion by Skip-attention Network with Hierarchical Folding. [Completion] [CVPR] End-to-End Learning Local Multi-View Descriptors for 3D Point Clouds. [Description] [CVPR] Convolution in the Cloud: Learning Deformable Kernels in 3D Graph Convolution Networks for Point Cloud Analysis. [other] [CVPR] On Isometry Robustness of Deep 3D Point Cloud Models Under Adversarial Attacks. [other] [CVPRW] AFDet: Anchor Free One Stage 3D Object Detection. [Detection.] [[ECCV]] EPNet: Enhancing Point Features with Image Semantics for 3D Object Detection. code [ECCV] 3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection. code [ECCV] GRNet: Gridding Residual Network for Dense Point Cloud Completion. code [ECCV] A Closer Look at Local Aggregation Operators in Point Cloud Analysis. pytorch/tensorflow [ECCV] Finding Your (3D) Center: 3D Object Detection Using a Learned Loss. [Detection.] [ECCV] H3DNet: 3D Object Detection Using Hybrid Geometric Primitives. pytorch [ECCV] Quaternion Equivariant Capsule Networks for 3D Point Clouds. [Classification] [ECCV] Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation. [Interpolation] [ECCV] PointPWC-Net: Cost Volume on Point Clouds for (Self-)Supervised Scene Flow Estimation. [Flow] [ECCV] H3DNet: 3D Object Detection Using Hybrid Geometric Primitives. pytorch [ECCV] ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds. [Fitting] [ECCV] Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions. code [ECCV] DPDist : Comparing Point Clouds Using Deep Point Cloud Distance. [Comparing] [ECCV] SSN: Shape Signature Networks for Multi-class Object Detection from Point Clouds. code [ECCV] PUGeo-Net: A Geometry-centric Network for 3D Point Cloud Upsampling. [Upsampling] [ECCV] AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds. [Perturbations] [ECCV] Learning Graph-Convolutional Representations for Point Cloud Denoising. [Denoising] [ECCV] Detail Preserved Point Cloud Completion via Separated Feature Aggregation. tensorflow [ECCV] Progressive Point Cloud Deconvolution Generation Network. code [ECCV] JSENet: Joint Semantic Segmentation and Edge Detection Network for 3D Point Clouds. code [ECCV] Shape Prior Deformation for Categorical 6D Object Pose and Size Estimation. pytorch [ECCV] Mapping in a cycle: Sinkhorn regularized unsupervised learning for point cloud shapes. [Correspondence] [ECCV] Pillar-based Object Detection for Autonomous Driving. tensorflow [ECCV] DH3D: Deep Hierarchical 3D Descriptors for Robust Large-Scale 6DoF Relocalization. pytorch [ECCV] Meshing Point Clouds with Predicted Intrinsic-Extrinsic Ratio Guidance. [Meshing] [ECCV] Discrete Point Flow Networks for Efficient Point Cloud Generation. [Generation] [ECCV] PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding. [Unsupervised,Understanding] [ECCV] Points2Surf: Learning Implicit Surfaces from Point Cloud Patches. [Surfaces] [ECCV] CAD-Deform: Deformable Fitting of CAD Models to 3D Scans. [Fitting] [ECCV] Weakly Supervised 3D Object Detection from Lidar Point Cloud. [Detection] [ECCV] Self-Prediction for Joint Instance and Semantic Segmentation of Point Clouds. [Segmentation] [ECCV] Virtual Multi-view Fusion for 3D Semantic Segmentation. [Segmentation] [ECCV] Searching Efficient 3D Architectures with Sparse Point-Voxel Convolution. [Segmentation] [ECCV] Multimodal Shape Completion via Conditional Generative Adversarial Networks. pytorch [ECCV] PointMixup: Augmentation for Point Clouds. code [ECCV] SPOT: Selective Point Cloud Voting for Better Proposal in Point Cloud Object Detection. [Detection] [ECCV] Rotation-robust Intersection over Union for 3D Object Detection. [3D IOU] [ECCV] SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification. [Classification, Completion] [ECCV] Efficient Outdoor 3D Point Cloud Semantic Segmentation for Critical Road Objects and Distributed Contexts. [Segmentation] [ECCV] CN: Channel Normalization For Point Cloud Recognition. [Recognition] [ECCV] Weakly-supervised 3D Shape Completion in the Wild. [Completion] [ECCV] Deep FusionNet for Point Cloud Semantic Segmentation. code \u00b6 [IROS] Cascaded Non-local Neural Network for Point Cloud Semantic Segmentation. [Segmentation] [IROS] Point Cloud Based Reinforcement Learning for Sim-to-Real and Partial Observability in Visual Navigation. [Navigation] [IROS] Factor Graph based 3D Multi-Object Tracking in Point Clouds. [Tracking] [IROS] Semantic Graph Based Place Recognition for 3D Point Clouds. [Place Recognition] \u00b6 [ACM MM] Weakly Supervised 3D Object Detection from Point Clouds. code [ACM MM] Differentiable Manifold Reconstruction for Point Cloud Denoising. pytorch [ACM MM] Campus3D: A Photogrammetry Point Cloud Benchmark for Hierarchical Understanding of Outdoor Scene. [Understanding] [WACV] FuseSeg: LiDAR Point Cloud Segmentation Fusing Multi-Modal Data. [seg. aut.] [WACV] Global Context Reasoning for Semantic Segmentation of 3D Point Clouds. [seg.] [WACV] PointPoseNet: Point Pose Network for Robust 6D Object Pose Estimation. [oth.] [BMVC] ASAP-Net: Attention and Structure Aware Point Cloud Sequence Segmentation. [Segmentation] \u00b6 [arXiv] Scan2Plan: Efficient Floorplan Generation from 3D Scans of Indoor Scenes. [oth.] [arXiv] Multimodal Shape Completion via Conditional Generative Adversarial Networks. [oth.] [arXiv] MANet: Multimodal Attention Network based Point-View fusion for 3D Shape Recognition. [cls.] [arXiv] siaNMS: Non-Maximum Suppression with Siamese Networks for Multi-Camera 3D Object Detection. [det.] [arXiv] SalsaNext: Fast Semantic Segmentation of LiDAR Point Clouds for Autonomous Driving. [code] [seg.] [arXiv] LaserFlow: Efficient and Probabilistic Object Detection and Motion Forecasting. [det. oth.] [arXiv] Feature Fusion Network Based on Attention Mechanism for 3D Semantic Segmentation of Point Clouds. [seg.] [arXiv] Confidence Guided Stereo 3D Object Detection with Split Depth Estimation. [det.] [arXiv] Self-supervised Point Set Local Descriptors for Point Cloud Registration. [reg.] [arXiv] How Powerful Are Randomly Initialized Pointcloud Set Functions?. [cls.] [arXiv] Bi-Directional Attention for Joint Instance and Semantic Segmentation in Point Clouds. [seg.] [arXiv] PointLoc: Deep Pose Regressor for LiDAR Point Cloud Localization. [oth.] [arXiv] 3D Object Detection From LiDAR Data Using Distance Dependent Feature Extraction. [det.] [arXiv] 3D Point Cloud Processing and Learning for Autonomous Driving. [oth.] [arXiv] PointHop++: A Lightweight Learning Model on Point Sets for 3D Classification. [cls.] [arXiv] PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree Conditions. [oth.] [arXiv] A Rotation-Invariant Framework for Deep Point Cloud Analysis. [oth.] [arXiv] Non-Local Part-Aware Point Cloud Denoising. [oth.] [arXiv] C-Flow: Conditional Generative Flow Models for Images and 3D Point Clouds. [oth.] [arXiv] DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares. [oth.] [arXiv] Real-time 3D object proposal generation and classification under limited processing resources. [det.] [arXiv] Multi-view Semantic Learning Network for Point Cloud Based 3D Object Detection. [seg.] [arXiv] Sequential Forecasting of 100,000 Points. [oth.] [arXiv] Toronto-3D: A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways. [seg.] [arXiv] Self-Supervised Learning for Domain Adaptation on Point-Clouds. [oth.] [arXiv] A Benchmark for Point Clouds Registration Algorithms. code [arXiv] SceneCAD: Predicting Object Alignments and Layouts in RGB-D Scans. [oth.] [arXiv] ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds. [oth.] [arXiv] Unsupervised Sequence Forecasting of 100,000 Points for Unsupervised Trajectory Forecasting. pytorch [arXiv] SK-Net: Deep Learning on Point Cloud via End-to-end Discovery of Spatial Keypoints. [cls.] [arXiv] Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions. pytorch [arXiv] Boundary-Aware Dense Feature Indicator for Single-Stage 3D Object Detection from Point Clouds. [det.] [arXiv] Bi-Directional Attention for Joint Instance and Semantic Segmentation in Point Clouds. [seg.] [arXiv] Scene Context Based Semantic Segmentation for 3D LiDAR Data in Dynamic Scene. [seg.] [arXiv] Quantifying Data Augmentation for LiDAR based 3D Object Detection. code [arXiv] Generative PointNet: Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification. [oth.] [arXiv] Deformation-Aware 3D Model Embedding and Retrieval. [oth.] [arXiv] Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation. [oth.] [arXiv] SSN: Shape Signature Networks for Multi-class Object Detection from Point Clouds. code [arXiv] SqueezeSegV3: Spatially-Adaptive Convolution for Efficient Point-Cloud Segmentation. code [arXiv] Reconfigurable Voxels: A New Representation for LiDAR-Based Point Clouds. [seg.] [arXiv] MNEW: Multi-domain Neighborhood Embedding and Weighting for Sparse Point Clouds Segmentation. [seg.] [arXiv] LightConvPoint: convolution for points. [cls.] [arXiv] 3D IoU-Net: IoU Guided 3D Object Detector for Point Clouds. [det.] [arXiv] Deep Learning for Image and Point Cloud Fusion in Autonomous Driving: A Review. [review.] [arXiv] Simulation-based Lidar Super-resolution for Ground Vehicles. tensorflow [arXiv] Deep Manifold Prior. [oth.] [arXiv] Airborne LiDAR Point Cloud Classification with Graph Attention Convolution Neural Network. [cls.] [arXiv] Semantic Correspondence via 2D-3D-2D Cycle. code [arXiv] DAPnet: A double self-attention convolutional network for segmentation of point clouds. [code] [seg.] [arXiv] DPDist : Comparing Point Clouds Using Deep Point Cloud Distance. [seg.] [arXiv] 3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection. [det.] [arXiv] Weakly Supervised Semantic Segmentation in 3D Graph-Structured Point Clouds of Wild Scenes. [seg.] [arXiv] CoReNet: Coherent 3D scene reconstruction from a single RGB image. [reconstruction.] [arXiv] MOPS-Net: A Matrix Optimization-driven Network forTask-Oriented 3D Point Cloud Downsampling. [sampling.] [arXiv] PointTriNet: Learned Triangulation of 3D Point Sets. [Triangulation.] [arXiv] Drosophila-Inspired 3D Moving Object Detection Based on Point Clouds. [detection.] [arXiv] Point Cloud Completion by Skip-attention Network with Hierarchical Folding. [Completion.] [arXiv] Dense-Resolution Network for Point Cloud Classification and Segmentation. [segmentation.] [arXiv] Exploiting Multi-Layer Grid Maps for Surround-View Semantic Segmentation of Sparse LiDAR Data. [segmentation.] [arXiv] Deep Learning for LiDAR Point Clouds in Autonomous Driving: A Review. [Review.] [arXiv] hapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds. [Generation.] [arXiv] Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection. [Detection.] [arXiv] PAI-Conv: Permutable Anisotropic Convolutional Networks for Learning on Point Clouds. [Classification.] [arXiv] ShapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds. [Generation.] [arXiv] SVGA-Net: Sparse Voxel-Graph Attention Network for 3D Object Detection from Point Clouds. [Detection.] [arXiv] Are We Hungry for 3D LiDAR Data for Semantic Segmentation? [Segmentation.] [arXiv] GRNet: Gridding Residual Network for Dense Point Cloud Completion. [Completion.] [arXiv] Learning 3D-3D Correspondences for One-shot Partial-to-partial Registration. [Registration.] [arXiv] Deep Octree-based CNNs with Output-Guided Skip Connections for 3D Shape and Scene Completion. [Completion.] [arXiv] 3D Point Cloud Feature Explanations Using Gradient-Based Methods. [other.] [arXiv] Stereo RGB and Deeper LIDAR Based Network for 3D Object Detection. [Detection.] [arXiv] H3DNet: 3D Object Detection Using Hybrid Geometric Primitives. pytorch [arXiv] Generative Sparse Detection Networks for 3D Single-shot Object Detection. [Detection.] [arXiv] Center-based 3D Object Detection and Tracking. pytorch [arXiv] 1 st Place Solution for Waymo Open Dataset Challenge -- 3D Detection and Domain Adaptation. [Detection.] [arXiv] 1 st Place Solutions for Waymo Open Dataset Challenges -- 2D and 3D Tracking. [Detection.] [arXiv] PIE-NET: Parametric Inference of Point Cloud Edges. [Edge Detection.] [arXiv] Point Set Voting for Partial Point Cloud Analysis. [Segmentation,Classification,Completion.] [arXiv] Geometric Attention for Prediction of Differential Properties in 3D Point Clouds. [Feature Line.] [arXiv] Local Grid Rendering Networks for 3D Object Detection in Point Clouds. [Detection.] [arXiv] Complete & Label: A Domain Adaptation Approach to Semantic Segmentation of LiDAR Point Clouds. [Segmentation.] [arXiv] Accelerating 3D Deep Learning with PyTorch3D. [PyTorch3D.] [arXiv] Part-Aware Data Augmentation for 3D Object Detection in Point Cloud. [Detection.] [arXiv] Cylinder3D: An Effective 3D Framework for Driving-scene LiDAR Semantic Segmentation. code [arXiv] CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations. [Representation.] [arXiv] Global Context Aware Convolutions for 3D Point Cloud Understanding. [Understanding.] [arXiv] LPMNet: Latent Part Modification and Generation for 3D Point Clouds. [Generation.] [arXiv] VPC-Net: Completion of 3D Vehicles from MLS Point Clouds. [Completion.] [arXiv] Projected-point-based Segmentation: A New Paradigm for LiDAR Point Cloud Segmentation. [Segmentation.] [arXiv] PAM:Point-wise Attention Module for 6D Object Pose Estimation. [Pose.] [arXiv] Self-Sampling for Neural Point Cloud Consolidation. [Consolidation.] [arXiv] Deterministic PointNetLK for Generalized Registration. [Registration.] \u00b6 [ICML] PointMask: Towards Interpretable and Bias-Resilient Point Cloud Processing. [Classification.] [ICRA] DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans. [seg.] [ICRA] PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation. [completion.] [ICRA] Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds. [cls.] [ICRA] Any Motion Detector: Learning Class-agnostic Scene Dynamics from a Sequence of LiDAR Point Clouds. [det.] [TPAMI] Spherical Kernel for Efficient Graph Convolution on 3D Point Clouds. [cls.] [ICLR] Unpaired Point Cloud Completion on Real Scans using Adversarial Training.[tensorflow] [com.] [ACIIDS] Semi-supervised Representation Learning for 3D Point Clouds. [oth.] \u00b6 [CG] ConvPoint: Continuous convolutions for point cloud processing. [oth.] \u00b6 [ISPRS] Deep point embedding for urban classification using ALS point clouds: A new perspective from local to global. [oth.] \u00b6 [GMP] LRC-Net: Learning Discriminative Features on Point Clouds by EncodingLocal Region Contexts. [cls.] \u00b6 [SPM] Deep Feature-preserving Normal Estimation for Point Cloud Filtering. [normal.] \u00b6 [Master Thesis] Neighborhood Pooling in Graph Neural Networks for 3D and 4D Semantic Segmentation. ['seg.'] - Datasets [KITTI] The KITTI Vision Benchmark Suite. [det.] [ModelNet] The Princeton ModelNet . [cls.] [ShapeNet] A collaborative dataset between researchers at Princeton, Stanford and TTIC. [seg.] [PartNet] The PartNet dataset provides fine grained part annotation of objects in ShapeNetCore. [seg.] [PartNet] PartNet benchmark from Nanjing University and National University of Defense Technology. [seg.] [S3DIS] The Stanford Large-Scale 3D Indoor Spaces Dataset. [seg.] [ScanNet] Richly-annotated 3D Reconstructions of Indoor Scenes. [cls. seg.] [Stanford 3D] The Stanford 3D Scanning Repository. [reg.] [UWA Dataset] . [cls. seg. reg.] [Princeton Shape Benchmark] The Princeton Shape Benchmark. [SYDNEY URBAN OBJECTS DATASET] This dataset contains a variety of common urban road objects scanned with a Velodyne HDL-64E LIDAR, collected in the CBD of Sydney, Australia. There are 631 individual scans of objects across classes of vehicles, pedestrians, signs and trees. [cls. match.] [ASL Datasets Repository(ETH)] This site is dedicated to provide datasets for the Robotics community with the aim to facilitate result evaluations and comparisons. [cls. match. reg. det] [Large-Scale Point Cloud Classification Benchmark(ETH)] This benchmark closes the gap and provides a large labelled 3D point cloud data set of natural scenes with over 4 billion points in total. [cls.] [Robotic 3D Scan Repository] The Canadian Planetary Emulation Terrain 3D Mapping Dataset is a collection of three-dimensional laser scans gathered at two unique planetary analogue rover test facilities in Canada. [Radish] The Robotics Data Set Repository (Radish for short) provides a collection of standard robotics data sets. [IQmulus & TerraMobilita Contest] The database contains 3D MLS data from a dense urban environment in Paris (France), composed of 300 million points. The acquisition was made in January 2013. [cls. seg. det.] [Oakland 3-D Point Cloud Dataset] This repository contains labeled 3-D point cloud laser data collected from a moving platform in a urban environment. [Robotic 3D Scan Repository] This repository provides 3D point clouds from robotic experiments\uff0clog files of robot runs and standard 3D data sets for the robotics community. [Ford Campus Vision and Lidar Data Set] The dataset is collected by an autonomous ground vehicle testbed, based upon a modified Ford F-250 pickup truck. [The Stanford Track Collection] This dataset contains about 14,000 labeled tracks of objects as observed in natural street scenes by a Velodyne HDL-64E S2 LIDAR. [PASCAL3D+] Beyond PASCAL: A Benchmark for 3D Object Detection in the Wild. [pos. det.] [3D MNIST] The aim of this dataset is to provide a simple way to get started with 3D computer vision problems such as 3D shape recognition. [cls.] [WAD] [ApolloScape] The datasets are provided by Baidu Inc. [tra. seg. det.] [nuScenes] The nuScenes dataset is a large-scale autonomous driving dataset. [PreSIL] Depth information, semantic segmentation (images), point-wise segmentation (point clouds), ground point labels (point clouds), and detailed annotations for all vehicles and people. [paper] [det. aut.] [3D Match] Keypoint Matching Benchmark, Geometric Registration Benchmark, RGB-D Reconstruction Datasets. [reg. rec. oth.] [BLVD] (a) 3D detection, (b) 4D tracking, \u00a9 5D interactive event recognition and (d) 5D intention prediction. [ICRA 2019 paper] [det. tra. aut. oth.] [PedX] 3D Pose Estimation of Pedestrians, more than 5,000 pairs of high-resolution (12MP) stereo images and LiDAR data along with providing 2D and 3D labels of pedestrians. [ICRA 2019 paper] [pos. aut.] [H3D] Full-surround 3D multi-object detection and tracking dataset. [ICRA 2019 paper] [det. tra. aut.] [Argoverse BY ARGO AI] Two public datasets (3D Tracking and Motion Forecasting) supported by highly detailed maps to test, experiment, and teach self-driving vehicles how to understand the world around them. CVPR 2019 paper [Matterport3D] RGB-D: 10,800 panoramic views from 194,400 RGB-D images. Annotations: surface reconstructions, camera poses, and 2D and 3D semantic segmentations. Keypoint matching, view overlap prediction, normal prediction from color, semantic segmentation, and scene classification. [3DV 2017 paper] [code] [blog] [SynthCity] SynthCity is a 367.9M point synthetic full colour Mobile Laser Scanning point cloud. Nine categories. [seg. aut.] [Lyft Level 5] Include high quality, human-labelled 3D bounding boxes of traffic agents, an underlying HD spatial semantic map. [det. seg. aut.] [SemanticKITTI] Sequential Semantic Segmentation, 28 classes, for autonomous driving. All sequences of KITTI odometry labeled. [ICCV 2019 paper] [seg. oth. aut.] [NPM3D] The Paris-Lille-3D has been produced by a Mobile Laser System (MLS) in two different cities in France (Paris and Lille). [seg.] [The Waymo Open Dataset] The Waymo Open Dataset is comprised of high resolution sensor data collected by Waymo self-driving cars in a wide variety of conditions. [det.] [A*3D: An Autonomous Driving Dataset in Challeging Environments] A*3D: An Autonomous Driving Dataset in Challeging Environments. [det.] [PointDA-10 Dataset] Domain Adaptation for point clouds. [Oxford Robotcar] The dataset captures many different combinations of weather, traffic and pedestrians. [cls. det. rec.] [WHU-TLS BENCHMARK] WHU-TLS benchmark dataset. [reg.] [DALES] DALES: A Large-scale Aerial LiDAR Data Set for Semantic Segmentation. [seg.]","title":"\u6d4b\u8bd5"},{"location":"test/#cvpr-hplflownet-hierarchical-permutohedral-lattice-flownet-for-scene-flow-estimation-on-large-scale-point-clouds-pytorch-oth","text":"[ICCV] Deep Hough Voting for 3D Object Detection in Point Clouds. [pytorch] [tensorflow] [det.] [ICCV] DeepGCNs: Can GCNs Go as Deep as CNNs? [tensorflow] [pytorch] [seg.] [ICCV] PU-GAN: a Point Cloud Upsampling Adversarial Network. [tensorflow] [oth.] [ICCV] 3D Point Cloud Learning for Large-scale Environment Analysis and Place Recognition. [rel. oth.] [ICCV] PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows. [pytorch] [oth.] [ICCV] Multi-Angle Point Cloud-VAE: Unsupervised Feature Learning for 3D Point Clouds from Multiple Angles by Joint Self-Reconstruction and Half-to-Half Prediction. [oth.] [ICCV] SO-HandNet: Self-Organizing Network for 3D Hand Pose Estimation with Semi-supervised Learning. [code] [pos.] [ICCV] DUP-Net: Denoiser and Upsampler Network for 3D Adversarial Point Clouds Defense. [oth.] [ICCV] Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data. [cls. dat.] [code] [dataset] [ICCV] KPConv: Flexible and Deformable Convolution for Point Clouds. [tensorflow] [cls. seg.] [ICCV] ShellNet: Efficient Point Cloud Convolutional Neural Networks using Concentric Shells Statistics. [project] [seg.] [ICCV] Point-Based Multi-View Stereo Network. [pytorch] [rec.] [ICCV] DensePoint: Learning Densely Contextual Representation for Efficient Point Cloud Processing. [pytorch] [cls. seg. oth.] [ICCV] DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud Registration. [reg.] [ICCV] 3D Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions. [pytorch] [oth.] [ICCV] Hierarchical Point-Edge Interaction Network for Point Cloud Semantic Segmentation. [seg.] [ICCV] Learning an Effective Equivariant 3D Descriptor Without Supervision. [oth.] [ICCV] Fully Convolutional Geometric Features. [pytorch] [reg.] [ICCV] LPD-Net: 3D Point Cloud Learning for Large-Scale Place Recognition and Environment Analysis. [oth. aut.] [ICCV] Total Denoising: Unsupervised Learning of 3D Point Cloud Cleaning. [tensorflow] [oth.] [ICCV] USIP: Unsupervised Stable Interest Point Detection from 3D Point Clouds. [pytorch] [oth.] [ICCV] Interpolated Convolutional Networks for 3D Point Cloud Understanding. [cls. seg.] [ICCV] PointCloud Saliency Maps. [code] [oth.] [ICCV] STD: Sparse-to-Dense 3D Object Detector for Point Cloud. [det. oth.] [ICCV] Accelerated Gravitational Point Set Alignment with Altered Physical Laws. [reg.] [ICCV] Deep Closest Point: Learning Representations for Point Cloud Registration. [reg.] [ICCV] Efficient Learning on Point Clouds with Basis Point Sets. [code] [cls. reg.] [ICCV] PointAE: Point Auto-encoder for 3D Statistical Shape and Texture Modelling. [rec.] [ICCV] Skeleton-Aware 3D Human Shape Reconstruction From Point Clouds. [rec.] [ICCV] Dynamic Points Agglomeration for Hierarchical Point Sets Learning. [pytorch] [cls. seg.] [ICCV] Unsupervised Multi-Task Feature Learning on Point Clouds. [cls. seg.] [ICCV] VV-NET: Voxel VAE Net with Group Convolutions for Point Cloud Segmentation. [tensorflow] [seg.] [ICCV] GraphX-Convolution for Point Cloud Deformation in 2D-to-3D Conversion. [pytorch] [rec.] [ICCV] MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences. [code] [cls. seg. oth.] [ICCV] Fast Point R-CNN. [det. aut.] [ICCV] Robust Variational Bayesian Point Set Registration. [reg.] [ICCV] DiscoNet: Shapes Learning on Disconnected Manifolds for 3D Editing. [rec. oth.] [ICCV] Learning an Effective Equivariant 3D Descriptor Without Supervision. [oth.] [ICCV] 3D Instance Segmentation via Multi-Task Metric Learning. [code] [seg.] [ICCV] 3D Face Modeling From Diverse Raw Scan Data. [rec.]","title":"[CVPR] HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-scale Point Clouds. [pytorch] [oth.]"},{"location":"test/#iccvw-range-adaptation-for-3d-object-detection-in-lidar-det-aut","text":"[NeurIPS] Self-Supervised Deep Learning on Point Clouds by Reconstructing Space. [cls. oth.] [NeurIPS] Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds. [tensorflow] [det. seg.] [NeurIPS] Exploiting Local and Global Structure for Point Cloud Semantic Segmentation with Contextual Point Representations. [tensorflow] [seg.] [NeurIPS] Point-Voxel CNN for Efficient 3D Deep Learning. [det. seg. aut.]","title":"[ICCVW] Range Adaptation for 3D Object Detection in LiDAR. [det. aut.]"},{"location":"test/#neurips-pointdan-a-multi-scale-3d-domain-adaption-network-for-point-cloud-representation-code-cls-oth","text":"","title":"[NeurIPS] PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation. [code] [cls. oth.]"},{"location":"test/#iclr-learning-localized-generative-models-for-3d-point-clouds-via-graph-convolution-oth","text":"","title":"[ICLR] Learning Localized Generative Models for 3D Point Clouds via Graph Convolution. [oth.]"},{"location":"test/#icmlw-lidar-sensor-modeling-and-data-augmentation-with-gans-for-autonomous-driving-det-oth-aut","text":"[AAAI] CAPNet: Continuous Approximation Projection For 3D Point Cloud Reconstruction Using 2D Supervision. [code] [rec.] [AAAI] Point2Sequence: Learning the Shape Representation of 3D Point Clouds with an Attention-based Sequence to Sequence Network. [tensorflow] [cls. seg.] [AAAI] Point Cloud Processing via Recurrent Set Encoding. [cls.] [AAAI] PVRNet: Point-View Relation Neural Network for 3D Shape Recognition. [pytorch] [cls. rel.]","title":"[ICMLW] LiDAR Sensor modeling and Data augmentation with GANs for Autonomous driving. [det. oth. aut.]"},{"location":"test/#aaai-hypergraph-neural-networks-pytorch-cls","text":"[TOG] Dynamic Graph CNN for Learning on Point Clouds. tensorflow ( https://github.com/WangYueFt/dgcnn )] [cls. seg.] [TOG] LOGAN: Unpaired Shape Transform in Latent Overcomplete Space. [tensorflow] [oth.]","title":"[AAAI] Hypergraph Neural Networks. [pytorch] [cls.]"},{"location":"test/#siggraph-asia-structurenet-hierarchical-graph-networks-for-3d-shape-generation-seg-oth","text":"[MM] MMJN: Multi-Modal Joint Networks for 3D Shape Recognition. [cls. rel.] [MM] 3D Point Cloud Geometry Compression on Deep Learning. [oth.] [MM] SRINet: Learning Strictly Rotation-Invariant Representations for Point Cloud Classification and Segmentation. [tensorflow] [cls. seg.] [MM] L2G Auto-encoder: Understanding Point Clouds by Local-to-Global Reconstruction with Hierarchical Self-Attention. [cls. rel.]","title":"[SIGGRAPH Asia] StructureNet: Hierarchical Graph Networks for 3D Shape Generation. [seg. oth.]"},{"location":"test/#mm-ground-aware-point-cloud-semantic-segmentation-for-autonomous-driving-code-seg-aut","text":"","title":"[MM] Ground-Aware Point Cloud Semantic Segmentation for Autonomous Driving. [code] [seg. aut.]"},{"location":"test/#icme-justlookup-one-millisecond-deep-feature-extraction-for-point-clouds-by-lookup-tables-cls-rel","text":"","title":"[ICME] Justlookup: One Millisecond Deep Feature Extraction for Point Clouds By Lookup Tables. [cls. rel.]"},{"location":"test/#icassp-3d-point-cloud-denoising-via-deep-neural-network-based-local-surface-estimation-code-oth","text":"","title":"[ICASSP] 3D Point Cloud Denoising via Deep Neural Network based Local Surface Estimation. [code] [oth.]"},{"location":"test/#bmvc-mitigating-the-hubness-problem-for-zero-shot-learning-of-3d-objects-cls","text":"[ICRA] Discrete Rotation Equivariance for Point Cloud Recognition. [pytorch] [cls.] [ICRA] SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud. [tensorflow] [seg. aut.] [ICRA] Detection and Tracking of Small Objects in Sparse 3D Laser Range Data. [det. tra. aut.] [ICRA] Oriented Point Sampling for Plane Detection in Unorganized Point Clouds. [det. seg.] [ICRA] Point Cloud Compression for 3D LiDAR Sensor Using Recurrent Neural Network with Residual Blocks. [pytorch] [oth.] [ICRA] Focal Loss in 3D Object Detection. [code] [det. aut.] [ICRA] PointNetGPD: Detecting Grasp Configurations from Point Sets. [pytorch] [det. seg.] [ICRA] 2D3D-MatchNet: Learning to Match Keypoints across 2D Image and 3D Point Cloud. [oth.] [ICRA] Speeding up Iterative Closest Point Using Stochastic Gradient Descent. [oth.] [ICRA] Uncertainty Estimation for Projecting Lidar Points Onto Camera Images for Moving Platforms. [oth.] [ICRA] SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data. [det. aut.] [ICRA] BLVD: Building A Large-scale 5D Semantics Benchmark for Autonomous Driving. [project] [dat. det. tra. aut. oth.] [ICRA] A Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications. [det.] [ICRA] Robust low-overlap 3-D point cloud registration for outlier rejection. [matlab] [reg.] [ICRA] Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution. [cls. seg.] [ICRA] Hierarchical Depthwise Graph Convolutional Neural Network for 3D Semantic Segmentation of Point Clouds. [seg.] [ICRA] Robust Generalized Point Set Registration Using Inhomogeneous Hybrid Mixture Models Via Expectation. [reg.] [ICRA] Dense 3D Visual Mapping via Semantic Simplification. [oth.] [ICRA] MVX-Net: Multimodal VoxelNet for 3D Object Detection. [det. aut.]","title":"[BMVC] Mitigating the Hubness Problem for Zero-Shot Learning of 3D Objects. [cls.]"},{"location":"test/#icra-cello-3d-estimating-the-covariance-of-icp-in-the-real-world-reg","text":"[IROS] EPN: Edge-Aware PointNet for Object Recognition from Multi-View 2.5D Point Clouds. [tensorflow] [cls. det.] [IROS] SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles. [oth.] [aut.]","title":"[ICRA] CELLO-3D: Estimating the Covariance of ICP in the Real World. [reg.]"},{"location":"test/#iros-pass3d-precise-and-accelerated-semantic-segmentation-for-3d-point-cloud-seg-aut","text":"","title":"[IROS] PASS3D: Precise and Accelerated Semantic Segmentation for 3D Point Cloud. [seg. aut.]"},{"location":"test/#iv-end-to-end-3d-pointcloud-semantic-segmentation-for-autonomous-driving-seg-aut","text":"","title":"[IV] End-to-End 3D-PointCloud Semantic Segmentation for Autonomous Driving. [seg.] [aut.]"},{"location":"test/#eurographics-workshop-generalizing-discrete-convolutions-for-unstructured-point-clouds-pytorch-cls-seg","text":"","title":"[Eurographics Workshop] Generalizing Discrete Convolutions for Unstructured Point Clouds. [pytorch] [cls. seg.]"},{"location":"test/#wacv-3dcapsule-extending-the-capsule-architecture-to-classify-3d-point-clouds-cls","text":"[3DV] Rotation Invariant Convolutions for 3D Point Clouds Deep Learning. [project] [cls. seg.]","title":"[WACV] 3DCapsule: Extending the Capsule Architecture to Classify 3D Point Clouds. [cls.]"},{"location":"test/#3dv-effective-rotation-invariant-point-cnn-with-spherical-harmonics-kernels-tensorflow-cls-seg-oth","text":"","title":"[3DV] Effective Rotation-invariant Point CNN with Spherical Harmonics kernels. [tensorflow] [cls. seg. oth.]"},{"location":"test/#tvcg-lassonet-deep-lasso-selection-of-3d-point-clouds-project-oth","text":"[arXiv] Fast 3D Line Segment Detection From Unorganized Point Cloud. [det.] [arXiv] Point-Cloud Saliency Maps. [tensorflow] [cls. oth.] [arXiv] Extending Adversarial Attacks and Defenses to Deep 3D Point Cloud Classifiers. [code] [oth.] [arxiv] Context Prediction for Unsupervised Deep Learning on Point Clouds. [cls. seg.] [arXiv] Points2Pix: 3D Point-Cloud to Image Translation using conditional Generative Adversarial Networks. [oth.] [arXiv] NeuralSampler: Euclidean Point Cloud Auto-Encoder and Sampler. [cls. oth.] [arXiv] 3D Graph Embedding Learning with a Structure-aware Loss Function for Point Cloud Semantic Instance Segmentation. [seg.] [arXiv] Zero-shot Learning of 3D Point Cloud Objects. [code] [cls.] [arXiv] Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud. [det. aut.] [arXiv] Real-time Multiple People Hand Localization in 4D Point Clouds. [det. oth.] [arXiv] Variational Graph Methods for Efficient Point Cloud Sparsification. [oth.] [arXiv] Neural Style Transfer for Point Clouds. [oth.] [arXiv] OREOS: Oriented Recognition of 3D Point Clouds in Outdoor Scenarios. [pos. oth.] [arXiv] FVNet: 3D Front-View Proposal Generation for Real-Time Object Detection from Point Clouds. [code] [det. aut.] [arXiv] Unpaired Point Cloud Completion on Real Scans using Adversarial Training. [oth.] [arXiv] MortonNet: Self-Supervised Learning of Local Features in 3D Point Clouds. [cls. seg.] [arXiv] DeepPoint3D: Learning Discriminative Local Descriptors using Deep Metric Learning on 3D Point Clouds. [cls. rel. oth.] [arXiv] Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds. [pytorch] [det. tra. aut.] [arXiv] Graph-based Inpainting for 3D Dynamic Point Clouds. [oth.] [arXiv] nuScenes: A multimodal dataset for autonomous driving. [link] [dat. det. tra. aut.] [arXiv] 3D Backbone Network for 3D Object Detection. [code] [det. aut.] [arXiv] Adversarial Autoencoders for Compact Representations of 3D Point Clouds. [pytorch] [rel. oth.] [arXiv] Linked Dynamic Graph CNN: Learning on Point Cloud via Linking Hierarchical Features. [cls. seg.] [arXiv] GAPNet: Graph Attention based Point Neural Network for Exploiting Local Feature of Point Cloud. [tensorflow] [cls. seg.] [arXiv] Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds. [tensorflow] [det. seg.] [arXiv] Differentiable Surface Splatting for Point-based Geometry Processing. [pytorch] [oth.] [arXiv] Spatial Transformer for 3D Points. [seg.] [arXiv] Point-Voxel CNN for Efficient 3D Deep Learning. [seg. det. aut.] [arXiv] Attentive Context Normalization for Robust Permutation-Equivariant Learning. [cls.] [arXiv] Neural Point-Based Graphics. [project] [oth.] [arXiv] Point Cloud Super Resolution with Adversarial Residual Graph Networks. [oth.] [tensorflow] [arXiv] Blended Convolution and Synthesis for Efficient Discrimination of 3D Shapes. [cls. rel.] [arXiv] StarNet: Targeted Computation for Object Detection in Point Clouds. [tensorflow] [det.] [arXiv] Efficient Tracking Proposals using 2D-3D Siamese Networks on LIDAR. [tra.] [arXiv] SAWNet: A Spatially Aware Deep Neural Network for 3D Point Cloud Processing. [tensorflow] [cls. seg.] [arXiv] Part-A^2 Net: 3D Part-Aware and Aggregation Neural Network for Object Detection from Point Cloud. [det. aut.] [arXiv] PyramNet: Point Cloud Pyramid Attention Network and Graph Embedding Module for Classification and Segmentation. [cls. seg.] [arXiv] PointRNN: Point Recurrent Neural Network for Moving Point Cloud Processing. [tensorflow] [tra. oth. aut.] [arXiv] PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points. [tensorflow] [cls. seg.] [arXiv] Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds. [oth.] [arXiv] 3D-Rotation-Equivariant Quaternion Neural Networks. [cls. rec.] [arXiv] Point2SpatialCapsule: Aggregating Features and Spatial Relationships of Local Regions on Point Clouds using Spatial-aware Capsules. [cls. rel. seg.] [arXiv] Geometric Feedback Network for Point Cloud Classification. [cls.] [arXiv] Relation Graph Network for 3D Object Detection in Point Clouds. [det.] [arXiv] Deformable Filter Convolution for Point Cloud Reasoning. [seg. det. aut.] [arXiv] PU-GCN: Point Cloud Upsampling via Graph Convolutional Network. [project] [oth.] [arXiv] Grid-GCN for Fast and Scalable Point Cloud Learning. [seg. cls.] [arXiv] PointPainting: Sequential Fusion for 3D Object Detection. [seg. det.] [arXiv] Transductive Zero-Shot Learning for 3D Point Cloud Classification. [cls.] [arXiv] Geometry Sharing Network for 3D Point Cloud Classification and Segmentation. [pytorch] [cls. seg.] [arvix] Deep Learning for 3D Point Clouds: A Survey. [code] [cls. det. tra. seg.] [arXiv] Spectral-GANs for High-Resolution 3D Point-cloud Generation. [rec. oth.] [arXiv] Point Attention Network for Semantic Segmentation of 3D Point Clouds. [seg.] [arXiv] PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation. [oth.] [arXiv] 3D Object Recognition with Ensemble Learning --- A Study of Point Cloud-Based Deep Learning Models. [cls. det.] 2020 [AAAI] Morphing and Sampling Network for Dense Point Cloud Completion. [pytorch] [oth.] [AAAI] TANet: Robust 3D Object Detection from Point Clouds with Triple Attention. [code] [det. aut.] [AAAI] Point2Node: Correlation Learning of Dynamic-Node for Point Cloud Feature Modeling. [seg. cls.] [AAAI] PRIN: Pointwise Rotation-Invariant Network. [seg. cls.] [AAAI] SK-Net: Deep Learning on Point Cloud via End-to-end Discovery of Spatial Keypoints. [oth] [AAAI] JSNet: Joint Instance and Semantic Segmentation of 3D Point Clouds. tensorflow [AAAI] ZoomNet: Part-Aware Adaptive Zooming Neural Network for 3D Object Detection. [det.]","title":"[TVCG] LassoNet: Deep Lasso-Selection of 3D Point Clouds. [project] [oth.]"},{"location":"test/#aaai-shape-oriented-convolution-neural-network-for-point-cloud-analysis-cls","text":"[CVPR] RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds. [tensorflow] [seg.] [CVPR] Learning multiview 3D point cloud registration. [code] [reg.] [CVPR] PF-Net: Point Fractal Network for 3D Point Cloud Completion. [pytorch] [oth.] [CVPR] ImVoteNet: Boosting 3D Object Detection in Point Clouds with Image Votes. [det.] [CVPR] Fusion-Aware Point Convolution for Online Semantic 3D Scene Segmentation. [pytorch] [seg.] [CVPR] AdaCoSeg: Adaptive Shape Co-Segmentation with Group Consistency Loss. [seg.] [CVPR] SA-SSD: Structure Aware Single-Stage 3D Object Detection from Point Cloud. [pytorch] [det.] [CVPR] PointAugment: an Auto-Augmentation Framework for Point Cloud Classification. [code] [classification.] [CVPR] Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud. tensorflow [CVPR] Multi-Path Region Mining For Weakly Supervised 3D Semantic Segmentation on Point Clouds. [seg.] [CVPR] Global-Local Bidirectional Reasoning for Unsupervised Representation Learning of 3D Point Clouds. pytorch [CVPR] PointGMM: a Neural GMM Network for Point Clouds. code [CVPR] RPM-Net: Robust Point Matching using Learned Features. [code] [seg.] [CVPR] Unsupervised Learning of Intrinsic Structural Representation Points. pytorch [CVPR] PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation. [pytorch] [seg.] [CVPR] 3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation. [seg.] [CVPR] DOPS: Learning to Detect 3D Objects and Predict their 3D Shapes. [det.] [CVPR] OccuSeg: Occupancy-aware 3D Instance Segmentation. [seg.] [CVPR] MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird's Eye View Maps. [oth.] [CVPR] Learning to Segment 3D Point Clouds in 2D Image Space. [pytorch] [seg] [CVPR] D3Feat: Joint Learning of Dense Detection and Description of 3D Local Features. [cls] [CVPR] PointASNL: Robust Point Clouds Processing using Nonlocal Neural Networks with Adaptive Sampling. [cls.] [CVPR] Physically Realizable Adversarial Examples for LiDAR Object Detection. [det.] [CVPR] HVNet: Hybrid Voxel Network for LiDAR Based 3D Object Detection. [det] [CVPR] LiDAR-based Online 3D Video Object Detection with Graph-based Message Passing and Spatiotemporal Transformer Attention. code [CVPR] PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation. [seg.] [CVPR] DualSDF: Semantic Shape Manipulation using a Two-Level Representation. code [CVPR] Disp R-CNN: Stereo 3D Object Detection via Shape Prior Guided Instance Disparity Estimation. pytorch [CVPR] End-to-End Pseudo-LiDAR for Image-Based 3D Object Detection. [code] [det.] [CVPR] Cascaded Refinement Network for Point Cloud Completion. code [CVPR] MLCVNet: Multi-Level Context VoteNet for 3D Object Detection. code [CVPR] Learning 3D Semantic Scene Graphs from 3D Indoor Reconstructions. [oth.] [CVPR] Joint Spatial-Temporal Optimization for Stereo 3D Object Tracking. [track.] [CVPR] StructEdit: Learning Structural Shape Variations. [project] [rec.] [CVPR] Connect-and-Slice: an hybrid approach for reconstructing 3D objects. [reconstruction.] [CVPR] SGAS: Sequential Greedy Architecture Search. [pytorch] ['cls.'] [CVPR oral] Deep Global Registration. ['reg.'] [CVPR] 3DSSD: Point-based 3D Single Stage Object Detector. [det] [CVPR] Going Deeper with Point Networks. pytorch [CVPR] Connect-and-Slice: an hybrid approach for reconstructing 3D objects. [reconstruction] [CVPR] Feature-metric Registration: A Fast Semi-supervised Approach for Robust Point Cloud Registration without Correspondences. [registration] [CVPR] From Image Collections to Point Clouds with Self-supervised Shape and Pose Networks. tensorflow [CVPR] PointPainting: Sequential Fusion for 3D Object Detection. [detection] [CVPR] xMUDA: Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation. [Segmentation] [CVPR] FroDO: From Detections to 3D Objects. [detection] [CVPR oral] OctSqueeze: Octree-Structured Entropy Model for LiDAR Compression. [Compression] [CVPR] Train in Germany, Test in The USA: Making 3D Object Detectors Generalize. code [CVPR oral] High-dimensional Convolutional Networks for Geometric Pattern Recognition. code [CVPR oral] P2B: Point-to-Box Network for 3D Object Tracking in Point Clouds. pytorch [CVPR] Associate-3Ddet: Perceptual-to-Conceptual Association for 3D Point Cloud Object Detection. [detection] [CVPR] RevealNet: Seeing Behind Objects in RGB-D Scans. [Completion] [CVPR] A Hierarchical Graph Network for 3D Object Detection on Point Clouds. [Detection] [CVPR] Density Based Clustering for 3D Object Detection in Point Clouds. [Detection] [CVPR] Joint 3D Instance Segmentation and Object Detection for Autonomous Driving. [Detection] [CVPR] Neural Implicit Embedding for Point Cloud Analysis. [Analysis] [CVPR] End-to-End 3D Point Cloud Instance Segmentation Without Detection. [Segmentation] [CVPR] Adaptive Hierarchical Down-Sampling for Point Cloud Classification. [Classification] [CVPR] Geometry and Learning Co-Supported Normal Estimation for Unstructured Point Cloud. [Normal] [CVPR] Weakly Supervised Semantic Point Cloud Segmentation: Towards 10x Fewer Labels. [Segmentation] [CVPR] SegGCN: Efficient 3D Point Cloud Segmentation With Fuzzy Spherical Kernel. [Segmentation] [CVPR] LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud Based Deep Networks. [Attack] [CVPR] SampleNet: Differentiable Point Cloud Sampling. [Sampling] [CVPR] Sequential 3D Human Pose and Shape Estimation From Point Clouds. [Pose] [CVPR] An Efficient PointLSTM for Point Clouds Based Gesture Recognition. [Recognition] [CVPR] Grid-GCN for Fast and Scalable Point Cloud Learning. [other] [CVPR] SpSequenceNet: Semantic Segmentation Network on 4D Point Clouds. [Segmentation] [CVPR] Point Cloud Completion by Skip-attention Network with Hierarchical Folding. [Completion] [CVPR] End-to-End Learning Local Multi-View Descriptors for 3D Point Clouds. [Description] [CVPR] Convolution in the Cloud: Learning Deformable Kernels in 3D Graph Convolution Networks for Point Cloud Analysis. [other] [CVPR] On Isometry Robustness of Deep 3D Point Cloud Models Under Adversarial Attacks. [other] [CVPRW] AFDet: Anchor Free One Stage 3D Object Detection. [Detection.] [[ECCV]] EPNet: Enhancing Point Features with Image Semantics for 3D Object Detection. code [ECCV] 3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection. code [ECCV] GRNet: Gridding Residual Network for Dense Point Cloud Completion. code [ECCV] A Closer Look at Local Aggregation Operators in Point Cloud Analysis. pytorch/tensorflow [ECCV] Finding Your (3D) Center: 3D Object Detection Using a Learned Loss. [Detection.] [ECCV] H3DNet: 3D Object Detection Using Hybrid Geometric Primitives. pytorch [ECCV] Quaternion Equivariant Capsule Networks for 3D Point Clouds. [Classification] [ECCV] Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation. [Interpolation] [ECCV] PointPWC-Net: Cost Volume on Point Clouds for (Self-)Supervised Scene Flow Estimation. [Flow] [ECCV] H3DNet: 3D Object Detection Using Hybrid Geometric Primitives. pytorch [ECCV] ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds. [Fitting] [ECCV] Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions. code [ECCV] DPDist : Comparing Point Clouds Using Deep Point Cloud Distance. [Comparing] [ECCV] SSN: Shape Signature Networks for Multi-class Object Detection from Point Clouds. code [ECCV] PUGeo-Net: A Geometry-centric Network for 3D Point Cloud Upsampling. [Upsampling] [ECCV] AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds. [Perturbations] [ECCV] Learning Graph-Convolutional Representations for Point Cloud Denoising. [Denoising] [ECCV] Detail Preserved Point Cloud Completion via Separated Feature Aggregation. tensorflow [ECCV] Progressive Point Cloud Deconvolution Generation Network. code [ECCV] JSENet: Joint Semantic Segmentation and Edge Detection Network for 3D Point Clouds. code [ECCV] Shape Prior Deformation for Categorical 6D Object Pose and Size Estimation. pytorch [ECCV] Mapping in a cycle: Sinkhorn regularized unsupervised learning for point cloud shapes. [Correspondence] [ECCV] Pillar-based Object Detection for Autonomous Driving. tensorflow [ECCV] DH3D: Deep Hierarchical 3D Descriptors for Robust Large-Scale 6DoF Relocalization. pytorch [ECCV] Meshing Point Clouds with Predicted Intrinsic-Extrinsic Ratio Guidance. [Meshing] [ECCV] Discrete Point Flow Networks for Efficient Point Cloud Generation. [Generation] [ECCV] PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding. [Unsupervised,Understanding] [ECCV] Points2Surf: Learning Implicit Surfaces from Point Cloud Patches. [Surfaces] [ECCV] CAD-Deform: Deformable Fitting of CAD Models to 3D Scans. [Fitting] [ECCV] Weakly Supervised 3D Object Detection from Lidar Point Cloud. [Detection] [ECCV] Self-Prediction for Joint Instance and Semantic Segmentation of Point Clouds. [Segmentation] [ECCV] Virtual Multi-view Fusion for 3D Semantic Segmentation. [Segmentation] [ECCV] Searching Efficient 3D Architectures with Sparse Point-Voxel Convolution. [Segmentation] [ECCV] Multimodal Shape Completion via Conditional Generative Adversarial Networks. pytorch [ECCV] PointMixup: Augmentation for Point Clouds. code [ECCV] SPOT: Selective Point Cloud Voting for Better Proposal in Point Cloud Object Detection. [Detection] [ECCV] Rotation-robust Intersection over Union for 3D Object Detection. [3D IOU] [ECCV] SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification. [Classification, Completion] [ECCV] Efficient Outdoor 3D Point Cloud Semantic Segmentation for Critical Road Objects and Distributed Contexts. [Segmentation] [ECCV] CN: Channel Normalization For Point Cloud Recognition. [Recognition] [ECCV] Weakly-supervised 3D Shape Completion in the Wild. [Completion]","title":"[AAAI] Shape-Oriented Convolution Neural Network for Point Cloud Analysis. [cls.]"},{"location":"test/#eccv-deep-fusionnet-for-point-cloud-semantic-segmentation-code","text":"[IROS] Cascaded Non-local Neural Network for Point Cloud Semantic Segmentation. [Segmentation] [IROS] Point Cloud Based Reinforcement Learning for Sim-to-Real and Partial Observability in Visual Navigation. [Navigation] [IROS] Factor Graph based 3D Multi-Object Tracking in Point Clouds. [Tracking]","title":"[ECCV] Deep FusionNet for Point Cloud Semantic Segmentation. code"},{"location":"test/#iros-semantic-graph-based-place-recognition-for-3d-point-clouds-place-recognition","text":"[ACM MM] Weakly Supervised 3D Object Detection from Point Clouds. code [ACM MM] Differentiable Manifold Reconstruction for Point Cloud Denoising. pytorch [ACM MM] Campus3D: A Photogrammetry Point Cloud Benchmark for Hierarchical Understanding of Outdoor Scene. [Understanding] [WACV] FuseSeg: LiDAR Point Cloud Segmentation Fusing Multi-Modal Data. [seg. aut.] [WACV] Global Context Reasoning for Semantic Segmentation of 3D Point Clouds. [seg.] [WACV] PointPoseNet: Point Pose Network for Robust 6D Object Pose Estimation. [oth.]","title":"[IROS] Semantic Graph Based Place Recognition for 3D Point Clouds. [Place Recognition]"},{"location":"test/#bmvc-asap-net-attention-and-structure-aware-point-cloud-sequence-segmentation-segmentation","text":"[arXiv] Scan2Plan: Efficient Floorplan Generation from 3D Scans of Indoor Scenes. [oth.] [arXiv] Multimodal Shape Completion via Conditional Generative Adversarial Networks. [oth.] [arXiv] MANet: Multimodal Attention Network based Point-View fusion for 3D Shape Recognition. [cls.] [arXiv] siaNMS: Non-Maximum Suppression with Siamese Networks for Multi-Camera 3D Object Detection. [det.] [arXiv] SalsaNext: Fast Semantic Segmentation of LiDAR Point Clouds for Autonomous Driving. [code] [seg.] [arXiv] LaserFlow: Efficient and Probabilistic Object Detection and Motion Forecasting. [det. oth.] [arXiv] Feature Fusion Network Based on Attention Mechanism for 3D Semantic Segmentation of Point Clouds. [seg.] [arXiv] Confidence Guided Stereo 3D Object Detection with Split Depth Estimation. [det.] [arXiv] Self-supervised Point Set Local Descriptors for Point Cloud Registration. [reg.] [arXiv] How Powerful Are Randomly Initialized Pointcloud Set Functions?. [cls.] [arXiv] Bi-Directional Attention for Joint Instance and Semantic Segmentation in Point Clouds. [seg.] [arXiv] PointLoc: Deep Pose Regressor for LiDAR Point Cloud Localization. [oth.] [arXiv] 3D Object Detection From LiDAR Data Using Distance Dependent Feature Extraction. [det.] [arXiv] 3D Point Cloud Processing and Learning for Autonomous Driving. [oth.] [arXiv] PointHop++: A Lightweight Learning Model on Point Sets for 3D Classification. [cls.] [arXiv] PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree Conditions. [oth.] [arXiv] A Rotation-Invariant Framework for Deep Point Cloud Analysis. [oth.] [arXiv] Non-Local Part-Aware Point Cloud Denoising. [oth.] [arXiv] C-Flow: Conditional Generative Flow Models for Images and 3D Point Clouds. [oth.] [arXiv] DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares. [oth.] [arXiv] Real-time 3D object proposal generation and classification under limited processing resources. [det.] [arXiv] Multi-view Semantic Learning Network for Point Cloud Based 3D Object Detection. [seg.] [arXiv] Sequential Forecasting of 100,000 Points. [oth.] [arXiv] Toronto-3D: A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways. [seg.] [arXiv] Self-Supervised Learning for Domain Adaptation on Point-Clouds. [oth.] [arXiv] A Benchmark for Point Clouds Registration Algorithms. code [arXiv] SceneCAD: Predicting Object Alignments and Layouts in RGB-D Scans. [oth.] [arXiv] ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds. [oth.] [arXiv] Unsupervised Sequence Forecasting of 100,000 Points for Unsupervised Trajectory Forecasting. pytorch [arXiv] SK-Net: Deep Learning on Point Cloud via End-to-end Discovery of Spatial Keypoints. [cls.] [arXiv] Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions. pytorch [arXiv] Boundary-Aware Dense Feature Indicator for Single-Stage 3D Object Detection from Point Clouds. [det.] [arXiv] Bi-Directional Attention for Joint Instance and Semantic Segmentation in Point Clouds. [seg.] [arXiv] Scene Context Based Semantic Segmentation for 3D LiDAR Data in Dynamic Scene. [seg.] [arXiv] Quantifying Data Augmentation for LiDAR based 3D Object Detection. code [arXiv] Generative PointNet: Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification. [oth.] [arXiv] Deformation-Aware 3D Model Embedding and Retrieval. [oth.] [arXiv] Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation. [oth.] [arXiv] SSN: Shape Signature Networks for Multi-class Object Detection from Point Clouds. code [arXiv] SqueezeSegV3: Spatially-Adaptive Convolution for Efficient Point-Cloud Segmentation. code [arXiv] Reconfigurable Voxels: A New Representation for LiDAR-Based Point Clouds. [seg.] [arXiv] MNEW: Multi-domain Neighborhood Embedding and Weighting for Sparse Point Clouds Segmentation. [seg.] [arXiv] LightConvPoint: convolution for points. [cls.] [arXiv] 3D IoU-Net: IoU Guided 3D Object Detector for Point Clouds. [det.] [arXiv] Deep Learning for Image and Point Cloud Fusion in Autonomous Driving: A Review. [review.] [arXiv] Simulation-based Lidar Super-resolution for Ground Vehicles. tensorflow [arXiv] Deep Manifold Prior. [oth.] [arXiv] Airborne LiDAR Point Cloud Classification with Graph Attention Convolution Neural Network. [cls.] [arXiv] Semantic Correspondence via 2D-3D-2D Cycle. code [arXiv] DAPnet: A double self-attention convolutional network for segmentation of point clouds. [code] [seg.] [arXiv] DPDist : Comparing Point Clouds Using Deep Point Cloud Distance. [seg.] [arXiv] 3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection. [det.] [arXiv] Weakly Supervised Semantic Segmentation in 3D Graph-Structured Point Clouds of Wild Scenes. [seg.] [arXiv] CoReNet: Coherent 3D scene reconstruction from a single RGB image. [reconstruction.] [arXiv] MOPS-Net: A Matrix Optimization-driven Network forTask-Oriented 3D Point Cloud Downsampling. [sampling.] [arXiv] PointTriNet: Learned Triangulation of 3D Point Sets. [Triangulation.] [arXiv] Drosophila-Inspired 3D Moving Object Detection Based on Point Clouds. [detection.] [arXiv] Point Cloud Completion by Skip-attention Network with Hierarchical Folding. [Completion.] [arXiv] Dense-Resolution Network for Point Cloud Classification and Segmentation. [segmentation.] [arXiv] Exploiting Multi-Layer Grid Maps for Surround-View Semantic Segmentation of Sparse LiDAR Data. [segmentation.] [arXiv] Deep Learning for LiDAR Point Clouds in Autonomous Driving: A Review. [Review.] [arXiv] hapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds. [Generation.] [arXiv] Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection. [Detection.] [arXiv] PAI-Conv: Permutable Anisotropic Convolutional Networks for Learning on Point Clouds. [Classification.] [arXiv] ShapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds. [Generation.] [arXiv] SVGA-Net: Sparse Voxel-Graph Attention Network for 3D Object Detection from Point Clouds. [Detection.] [arXiv] Are We Hungry for 3D LiDAR Data for Semantic Segmentation? [Segmentation.] [arXiv] GRNet: Gridding Residual Network for Dense Point Cloud Completion. [Completion.] [arXiv] Learning 3D-3D Correspondences for One-shot Partial-to-partial Registration. [Registration.] [arXiv] Deep Octree-based CNNs with Output-Guided Skip Connections for 3D Shape and Scene Completion. [Completion.] [arXiv] 3D Point Cloud Feature Explanations Using Gradient-Based Methods. [other.] [arXiv] Stereo RGB and Deeper LIDAR Based Network for 3D Object Detection. [Detection.] [arXiv] H3DNet: 3D Object Detection Using Hybrid Geometric Primitives. pytorch [arXiv] Generative Sparse Detection Networks for 3D Single-shot Object Detection. [Detection.] [arXiv] Center-based 3D Object Detection and Tracking. pytorch [arXiv] 1 st Place Solution for Waymo Open Dataset Challenge -- 3D Detection and Domain Adaptation. [Detection.] [arXiv] 1 st Place Solutions for Waymo Open Dataset Challenges -- 2D and 3D Tracking. [Detection.] [arXiv] PIE-NET: Parametric Inference of Point Cloud Edges. [Edge Detection.] [arXiv] Point Set Voting for Partial Point Cloud Analysis. [Segmentation,Classification,Completion.] [arXiv] Geometric Attention for Prediction of Differential Properties in 3D Point Clouds. [Feature Line.] [arXiv] Local Grid Rendering Networks for 3D Object Detection in Point Clouds. [Detection.] [arXiv] Complete & Label: A Domain Adaptation Approach to Semantic Segmentation of LiDAR Point Clouds. [Segmentation.] [arXiv] Accelerating 3D Deep Learning with PyTorch3D. [PyTorch3D.] [arXiv] Part-Aware Data Augmentation for 3D Object Detection in Point Cloud. [Detection.] [arXiv] Cylinder3D: An Effective 3D Framework for Driving-scene LiDAR Semantic Segmentation. code [arXiv] CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations. [Representation.] [arXiv] Global Context Aware Convolutions for 3D Point Cloud Understanding. [Understanding.] [arXiv] LPMNet: Latent Part Modification and Generation for 3D Point Clouds. [Generation.] [arXiv] VPC-Net: Completion of 3D Vehicles from MLS Point Clouds. [Completion.] [arXiv] Projected-point-based Segmentation: A New Paradigm for LiDAR Point Cloud Segmentation. [Segmentation.] [arXiv] PAM:Point-wise Attention Module for 6D Object Pose Estimation. [Pose.] [arXiv] Self-Sampling for Neural Point Cloud Consolidation. [Consolidation.]","title":"[BMVC] ASAP-Net: Attention and Structure Aware Point Cloud Sequence Segmentation. [Segmentation]"},{"location":"test/#arxiv-deterministic-pointnetlk-for-generalized-registration-registration","text":"[ICML] PointMask: Towards Interpretable and Bias-Resilient Point Cloud Processing. [Classification.] [ICRA] DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans. [seg.] [ICRA] PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation. [completion.] [ICRA] Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds. [cls.] [ICRA] Any Motion Detector: Learning Class-agnostic Scene Dynamics from a Sequence of LiDAR Point Clouds. [det.] [TPAMI] Spherical Kernel for Efficient Graph Convolution on 3D Point Clouds. [cls.] [ICLR] Unpaired Point Cloud Completion on Real Scans using Adversarial Training.[tensorflow] [com.]","title":"[arXiv] Deterministic PointNetLK for Generalized Registration. [Registration.]"},{"location":"test/#aciids-semi-supervised-representation-learning-for-3d-point-clouds-oth","text":"","title":"[ACIIDS] Semi-supervised Representation Learning for 3D Point Clouds. [oth.]"},{"location":"test/#cg-convpoint-continuous-convolutions-for-point-cloud-processing-oth","text":"","title":"[CG] ConvPoint: Continuous convolutions for point cloud processing. [oth.]"},{"location":"test/#isprs-deep-point-embedding-for-urban-classification-using-als-point-clouds-a-new-perspective-from-local-to-global-oth","text":"","title":"[ISPRS] Deep point embedding for urban classification using ALS point clouds: A new perspective from local to global. [oth.]"},{"location":"test/#gmp-lrc-net-learning-discriminative-features-on-point-clouds-by-encodinglocal-region-contexts-cls","text":"","title":"[GMP] LRC-Net: Learning Discriminative Features on Point Clouds by EncodingLocal Region Contexts. [cls.]"},{"location":"test/#spm-deep-feature-preserving-normal-estimation-for-point-cloud-filtering-normal","text":"[Master Thesis] Neighborhood Pooling in Graph Neural Networks for 3D and 4D Semantic Segmentation. ['seg.']","title":"[SPM] Deep Feature-preserving Normal Estimation for Point Cloud Filtering. [normal.]"},{"location":"Compiler-Principle/1/","text":"\u4f5c\u4e1a\u4e00 [\u7b2c\u4e09\u7ae0] \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf \u00b6 \u539a\u4e66 3.3.2 \u00b6 \u7531a\u4e0eb\u7ec4\u6210\u7684\uff0c\u524d\u7f00\u548c\u540e\u7f00\u5747\u4e3aa\u7684\u957f\u5ea6\u5927\u4e8e\u7b49\u4e8e2\u7684\u4e32 \u539a\u4e66 3.3.5 \u00b6 \u5b9a\u4e49\u03b2\u4e3a\u6240\u6709\u975e\u5143\u97f3\u5c0f\u5199\u5b57\u6bcd\u7684\u96c6\u5408\uff0c\u5219\u5176\u6b63\u5219\u8868\u8fbe\u5f0f\u4e3a: \\(\u03b2^* a(a|\u03b2)^* e(e|\u03b2)^* i(i|\u03b2)^* o(o|\u03b2)^* u(u|\u03b2)^*\\) \u539a\u4e66 3.6.3 \u00b6 0 -> 1 -> 2 -> 2 -> 3 0 -> 1 -> 1 -> 1 -> 1 \u80fd\u63a5\u53d7, 0 -> 1 -> 2 -> 2 -> 3 \u539a\u4e66 3.6.5 \u00b6 \u72b6\u6001 a b \\(\\epsilon\\) 0 {0,1} {0} \\(\\emptyset\\) 1 {1,2} {1} \\(\\emptyset\\) 2 {2} {2,3} {0} 3 \\(\\emptyset\\) \\(\\emptyset\\) \\(\\emptyset\\)","title":"\u4f5c\u4e1a1"},{"location":"Compiler-Principle/1/#_1","text":"","title":"\u4f5c\u4e1a\u4e00 [\u7b2c\u4e09\u7ae0]"},{"location":"Compiler-Principle/1/#151220129","text":"","title":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf"},{"location":"Compiler-Principle/1/#332","text":"\u7531a\u4e0eb\u7ec4\u6210\u7684\uff0c\u524d\u7f00\u548c\u540e\u7f00\u5747\u4e3aa\u7684\u957f\u5ea6\u5927\u4e8e\u7b49\u4e8e2\u7684\u4e32","title":"\u539a\u4e66 3.3.2"},{"location":"Compiler-Principle/1/#335","text":"\u5b9a\u4e49\u03b2\u4e3a\u6240\u6709\u975e\u5143\u97f3\u5c0f\u5199\u5b57\u6bcd\u7684\u96c6\u5408\uff0c\u5219\u5176\u6b63\u5219\u8868\u8fbe\u5f0f\u4e3a: \\(\u03b2^* a(a|\u03b2)^* e(e|\u03b2)^* i(i|\u03b2)^* o(o|\u03b2)^* u(u|\u03b2)^*\\)","title":"\u539a\u4e66 3.3.5"},{"location":"Compiler-Principle/1/#363","text":"0 -> 1 -> 2 -> 2 -> 3 0 -> 1 -> 1 -> 1 -> 1 \u80fd\u63a5\u53d7, 0 -> 1 -> 2 -> 2 -> 3","title":"\u539a\u4e66 3.6.3"},{"location":"Compiler-Principle/1/#365","text":"\u72b6\u6001 a b \\(\\epsilon\\) 0 {0,1} {0} \\(\\emptyset\\) 1 {1,2} {1} \\(\\emptyset\\) 2 {2} {2,3} {0} 3 \\(\\emptyset\\) \\(\\emptyset\\) \\(\\emptyset\\)","title":"\u539a\u4e66 3.6.5"},{"location":"Compiler-Principle/10/","text":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a10 \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf nju_wzy@163.com 7.2.4 \u00b6 int y \u53c2\u6570 g(y) \u8fd4\u56de\u503c \u8c03\u7528\u51fd\u6570g\u7684\u6307\u9488 \u63a7\u5236\u94fe int j \u5c40\u90e8\u53d8\u91cf int x \u53c2\u6570 f(x) \u8fd4\u56de\u503c g\u7684\u6307\u9488 \u63a7\u5236\u94fe int i \u5c40\u90e8\u53d8\u91cf","title":"\u4f5c\u4e1a10"},{"location":"Compiler-Principle/10/#10","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf nju_wzy@163.com","title":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a10"},{"location":"Compiler-Principle/10/#724","text":"int y \u53c2\u6570 g(y) \u8fd4\u56de\u503c \u8c03\u7528\u51fd\u6570g\u7684\u6307\u9488 \u63a7\u5236\u94fe int j \u5c40\u90e8\u53d8\u91cf int x \u53c2\u6570 f(x) \u8fd4\u56de\u503c g\u7684\u6307\u9488 \u63a7\u5236\u94fe int i \u5c40\u90e8\u53d8\u91cf","title":"7.2.4"},{"location":"Compiler-Principle/11/","text":"\u7f16\u8bd1\u539f\u7406 \u7b2c11\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com 7.5.2 \u00b6 D,G,F,I\u7684\u5f15\u7528\u8ba1\u6570\u51cf1\uff0cH\u7684\u5f15\u7528\u8ba1\u6570\u51cf2,D,F,G\u7684\u5f15\u7528\u6b21\u6570\u7b49\u4e8e0\uff0c\u56e0\u6b64\u88ab\u91ca\u653e\u7a7a\u95f4\u3002 7.6.1 \u00b6 \u521d\u59cb\u5316\uff0c\u5c06\u6240\u6709\u8282\u70b9reached=0\uff0c\u4ee3\u8868\u6240\u6709\u70b9\u90fd\u65e0\u6cd5\u5230\u8fbe\u3002 A,B\u4f5c\u4e3a\u6839\u8282\u70b9\uff0c\u5c06A.reached=1, B.reached=1\u3002 unscanned=[A,B] E.reached=1 unscanned=[B,E] C.reached=1 unscanned=[E,C] H.reached=1 unscanned=[C,H] I.reached=1 unscanned=[H,I] unscanned=[I] unscanned=[] \u7531\u4e8eDFG\u7684reached=0\uff0c\u5c06D,F,G\u7a7a\u95f4\u91ca\u653e 8.2.2 \u00b6 LD R1,i MUL R1,R1,#4 LD R2,a(R1) ST x,R2 LD R3,j MUL R3,R3,#4 LD R4,b(R3) ST y,R4 ST a(R1),R4 ST b(R3),R2 LD R1,i MUL R1,R1,#4 LD R2,a(R1) ST x,R2 LD R1,b(R1) ST y,R1 MUL R1,R2,R1 ST z,R1 8.2.4 \u00b6 LD R1,x LD R2,y SUB R1,R1,R2 BLTZ R1,L1 LD R1,#0 ST z,R1 BR L2 L1: LD R1,#1 ST z,R1","title":"\u4f5c\u4e1a11"},{"location":"Compiler-Principle/11/#11","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com","title":"\u7f16\u8bd1\u539f\u7406 \u7b2c11\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/11/#752","text":"D,G,F,I\u7684\u5f15\u7528\u8ba1\u6570\u51cf1\uff0cH\u7684\u5f15\u7528\u8ba1\u6570\u51cf2,D,F,G\u7684\u5f15\u7528\u6b21\u6570\u7b49\u4e8e0\uff0c\u56e0\u6b64\u88ab\u91ca\u653e\u7a7a\u95f4\u3002","title":"7.5.2"},{"location":"Compiler-Principle/11/#761","text":"\u521d\u59cb\u5316\uff0c\u5c06\u6240\u6709\u8282\u70b9reached=0\uff0c\u4ee3\u8868\u6240\u6709\u70b9\u90fd\u65e0\u6cd5\u5230\u8fbe\u3002 A,B\u4f5c\u4e3a\u6839\u8282\u70b9\uff0c\u5c06A.reached=1, B.reached=1\u3002 unscanned=[A,B] E.reached=1 unscanned=[B,E] C.reached=1 unscanned=[E,C] H.reached=1 unscanned=[C,H] I.reached=1 unscanned=[H,I] unscanned=[I] unscanned=[] \u7531\u4e8eDFG\u7684reached=0\uff0c\u5c06D,F,G\u7a7a\u95f4\u91ca\u653e","title":"7.6.1"},{"location":"Compiler-Principle/11/#822","text":"LD R1,i MUL R1,R1,#4 LD R2,a(R1) ST x,R2 LD R3,j MUL R3,R3,#4 LD R4,b(R3) ST y,R4 ST a(R1),R4 ST b(R3),R2 LD R1,i MUL R1,R1,#4 LD R2,a(R1) ST x,R2 LD R1,b(R1) ST y,R1 MUL R1,R2,R1 ST z,R1","title":"8.2.2"},{"location":"Compiler-Principle/11/#824","text":"LD R1,x LD R2,y SUB R1,R1,R2 BLTZ R1,L1 LD R1,#0 ST z,R1 BR L2 L1: LD R1,#1 ST z,R1","title":"8.2.4"},{"location":"Compiler-Principle/12/","text":"\u7f16\u8bd1\u539f\u7406 \u7b2c12\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com \u7b2c\u4e00\u9898 8.5.1 \u00b6 \u7b2c\u4e8c\u9898 \u00b6 \u7b2c\u4e09\u9898 8.6.1 \u00b6 t1 = a t2 = b * c t3 = t1 + t2 x = t3","title":"\u4f5c\u4e1a12"},{"location":"Compiler-Principle/12/#12","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com","title":"\u7f16\u8bd1\u539f\u7406 \u7b2c12\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/12/#851","text":"","title":"\u7b2c\u4e00\u9898 8.5.1"},{"location":"Compiler-Principle/12/#_1","text":"","title":"\u7b2c\u4e8c\u9898"},{"location":"Compiler-Principle/12/#861","text":"t1 = a t2 = b * c t3 = t1 + t2 x = t3","title":"\u7b2c\u4e09\u9898 8.6.1"},{"location":"Compiler-Principle/13/","text":"\u7f16\u8bd1\u539f\u7406 \u7b2c13\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com \u7b2c\u4e00\u9898 8.6.5 \u00b6 t1 = b * c LD R1, b LD R2, c MUL R1, R1, R2 t2 = a LD R2, a t3 = t1 + t2 ADD R1, R1, R2 x = t3 ST x, R1 R1 R2 a b c x t1 t2 t3 a b c x t1 c a b c,R2 x R1 t1 a,t2 a,R2 b c x R1 R2 t3 a,t2 a,R2 b c x R2 R1 t3 a,t2 a,R2 n c x,R1 R2 R1 \u7b2c\u4e8c\u9898 9.1.1 \u00b6 \u57fa\u672c\u5757 \\(B_3,B_4\\) \u662f\u4e00\u4e2a\u5faa\u73af\uff0c\u57fa\u672c\u5757 \\(B_2,B_3,B_4,B_5\\) \u662f\u53e6\u4e00\u4e2a\u5faa\u73af\u3002 (3) c = 1 + b (4) d = c - 1 (6) d = 1 + b (8) b = 1 + b (9) e = c - 1 \u5bf9\u4e8e\u5faa\u73af \\(B_3,B_4\\) \u6765\u8bf4\uff0c \\(a+b\\) \u662f\u5168\u5c40\u516c\u5171\u5b50\u8868\u8fbe\u5f0f \u5bf9\u4e8e\u5faa\u73af \\(B_2,B_3,B_4,B_5\\) \u6765\u8bf4\uff0c(6)(8)\u7684 \\(a+b\\) \uff0c(9)\u7684 \\(c-a\\) \u662f\u5168\u5c40\u516c\u5171\u5b50\u8868\u8fbe\u5f0f \u7565 \u5bf9\u4e8e\u5faa\u73af \\(B_3,B_4\\) \u6765\u8bf4\uff0c \\(a+b\\) \u662f\u5168\u90e8\u5faa\u73af\u4e0d\u53d8\u8ba1\u7b97 \u5bf9\u4e8e\u5faa\u73af \\(B_2,B_3,B_4,B_5\\) \u6765\u8bf4\uff0c\u6ca1\u6709\u5168\u90e8\u5faa\u73af\u4e0d\u53d8\u8ba1\u7b97 \u7b2c\u4e09\u9898 9.1.4 \u00b6 dp = 0 i = 0 t1 = 0 L: t2 = A[t1] t3 = B[t1] t4 = t2 * t3 dp = dp + t4 i = i + 1 t1 = t1 + 8 if i<n goto L","title":"\u4f5c\u4e1a13"},{"location":"Compiler-Principle/13/#13","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com","title":"\u7f16\u8bd1\u539f\u7406 \u7b2c13\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/13/#865","text":"t1 = b * c LD R1, b LD R2, c MUL R1, R1, R2 t2 = a LD R2, a t3 = t1 + t2 ADD R1, R1, R2 x = t3 ST x, R1 R1 R2 a b c x t1 t2 t3 a b c x t1 c a b c,R2 x R1 t1 a,t2 a,R2 b c x R1 R2 t3 a,t2 a,R2 b c x R2 R1 t3 a,t2 a,R2 n c x,R1 R2 R1","title":"\u7b2c\u4e00\u9898 8.6.5"},{"location":"Compiler-Principle/13/#911","text":"\u57fa\u672c\u5757 \\(B_3,B_4\\) \u662f\u4e00\u4e2a\u5faa\u73af\uff0c\u57fa\u672c\u5757 \\(B_2,B_3,B_4,B_5\\) \u662f\u53e6\u4e00\u4e2a\u5faa\u73af\u3002 (3) c = 1 + b (4) d = c - 1 (6) d = 1 + b (8) b = 1 + b (9) e = c - 1 \u5bf9\u4e8e\u5faa\u73af \\(B_3,B_4\\) \u6765\u8bf4\uff0c \\(a+b\\) \u662f\u5168\u5c40\u516c\u5171\u5b50\u8868\u8fbe\u5f0f \u5bf9\u4e8e\u5faa\u73af \\(B_2,B_3,B_4,B_5\\) \u6765\u8bf4\uff0c(6)(8)\u7684 \\(a+b\\) \uff0c(9)\u7684 \\(c-a\\) \u662f\u5168\u5c40\u516c\u5171\u5b50\u8868\u8fbe\u5f0f \u7565 \u5bf9\u4e8e\u5faa\u73af \\(B_3,B_4\\) \u6765\u8bf4\uff0c \\(a+b\\) \u662f\u5168\u90e8\u5faa\u73af\u4e0d\u53d8\u8ba1\u7b97 \u5bf9\u4e8e\u5faa\u73af \\(B_2,B_3,B_4,B_5\\) \u6765\u8bf4\uff0c\u6ca1\u6709\u5168\u90e8\u5faa\u73af\u4e0d\u53d8\u8ba1\u7b97","title":"\u7b2c\u4e8c\u9898 9.1.1"},{"location":"Compiler-Principle/13/#914","text":"dp = 0 i = 0 t1 = 0 L: t2 = A[t1] t3 = B[t1] t4 = t2 * t3 dp = dp + t4 i = i + 1 t1 = t1 + 8 if i<n goto L","title":"\u7b2c\u4e09\u9898 9.1.4"},{"location":"Compiler-Principle/14/","text":"\u7f16\u8bd1\u539f\u7406 \u7b2c14\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com \u7b2c\u4e00\u9898 9.2.1 \u00b6 gen kill \\(B_1\\) 1,2 8,10,11 \\(B_2\\) 3,4 5,6 \\(B_3\\) 5 4,6 \\(B_4\\) 6,7 4,5,9 \\(B_5\\) 8,9 2,7,11 \\(B_6\\) 10,11 1,2,8 In Out \\(B_1\\) \\(\\emptyset\\) 1,2 \\(B_2\\) 1,2,3,5,8,9 1,2,3,4,8,9 \\(B_3\\) 1,2,3,4,6,7,8,9 1,2,3,5,7,8,9 \\(B_4\\) 1,2,3,5,7,8,9 1,2,3,6,7,8 \\(B_5\\) 1,2,3,5,7,8,9 1,3,5,8,9 \\(B_6\\) 1,3,5,8,9 3,5,9,10,11 \u7b2c\u4e8c\u9898 9.2.3 \u00b6 def use \\(B_1\\) a,b \\(\\O\\) \\(B_2\\) c,d a,b \\(B_3\\) \\(\\O\\) b,d \\(B_4\\) d a,b,e \\(B_5\\) e a,b,c \\(B_6\\) a b,d In Out \\(B_1\\) e a,b,e \\(B_2\\) a,b,e a,b,c,d,e \\(B_3\\) a,b,c,d,e a,b,c,d,e \\(B_4\\) a,b,c,e a,b,c,d,e \\(B_5\\) a,b,c,d a,b,d \\(B_6\\) b,d \\(\\O\\)","title":"\u4f5c\u4e1a14"},{"location":"Compiler-Principle/14/#14","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf wuzy.nju@gmail.com","title":"\u7f16\u8bd1\u539f\u7406 \u7b2c14\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/14/#921","text":"gen kill \\(B_1\\) 1,2 8,10,11 \\(B_2\\) 3,4 5,6 \\(B_3\\) 5 4,6 \\(B_4\\) 6,7 4,5,9 \\(B_5\\) 8,9 2,7,11 \\(B_6\\) 10,11 1,2,8 In Out \\(B_1\\) \\(\\emptyset\\) 1,2 \\(B_2\\) 1,2,3,5,8,9 1,2,3,4,8,9 \\(B_3\\) 1,2,3,4,6,7,8,9 1,2,3,5,7,8,9 \\(B_4\\) 1,2,3,5,7,8,9 1,2,3,6,7,8 \\(B_5\\) 1,2,3,5,7,8,9 1,3,5,8,9 \\(B_6\\) 1,3,5,8,9 3,5,9,10,11","title":"\u7b2c\u4e00\u9898 9.2.1"},{"location":"Compiler-Principle/14/#923","text":"def use \\(B_1\\) a,b \\(\\O\\) \\(B_2\\) c,d a,b \\(B_3\\) \\(\\O\\) b,d \\(B_4\\) d a,b,e \\(B_5\\) e a,b,c \\(B_6\\) a b,d In Out \\(B_1\\) e a,b,e \\(B_2\\) a,b,e a,b,c,d,e \\(B_3\\) a,b,c,d,e a,b,c,d,e \\(B_4\\) a,b,c,e a,b,c,d,e \\(B_5\\) a,b,c,d a,b,d \\(B_6\\) b,d \\(\\O\\)","title":"\u7b2c\u4e8c\u9898 9.2.3"},{"location":"Compiler-Principle/2/","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf \u00b6 \u539a\u4e66 3.7.1 \u00b6 (2)\u4e00\u4e2a\u72b6\u6001 \\(\\epsilon-closure(0)=\\{0\\}=A\\) \\(Dtran[A,a] = \\epsilon-closure(0,1) = \\{0,1\\} = B\\) \\(Dtran[A,b] = \\epsilon-closure(0) = A\\) \\(Dtran[B,a] = \\epsilon-closure(0,1,2) = \\{0,1,2\\} = C\\) \\(Dtran[B,b] = \\epsilon-closure(0,1) = B\\) \\(Dtran[C,a] = \\epsilon-closure(0,1,2) = C\\) \\(Dtran[C,b] = \\epsilon-closure(0,1,2,3) = D\\) \\(Dtran[D,a] = \\epsilon-closure(0,1,2) = C\\) \\(Dtran[D,b] = \\epsilon-closure(0,1,2,4) = D\\) NFA DFA a b {0} A B A {0,1} B C B {0,1,2} C C D {0,1,2,3} D C D 4.2.1 \u00b6 \\(S \\rightarrow SS* \\rightarrow SS+S* \\rightarrow aS+S* \\rightarrow aa+S* \\rightarrow aa+a*\\) \\(S \\rightarrow SS* \\rightarrow Sa* \\rightarrow SS+a* \\rightarrow Sa+a* \\rightarrow aa+a*\\) \u5982\u4e0b\u56fe \u7565 \u6240\u6709\u52a0\u6cd5\u548c\u4e58\u6cd5\u6df7\u5408\u7684a\u7684\u540e\u7f00\u8868\u8fbe\u5f0f\u96c6\u5408","title":"\u4f5c\u4e1a2"},{"location":"Compiler-Principle/2/#151220129","text":"","title":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf"},{"location":"Compiler-Principle/2/#371","text":"(2)\u4e00\u4e2a\u72b6\u6001 \\(\\epsilon-closure(0)=\\{0\\}=A\\) \\(Dtran[A,a] = \\epsilon-closure(0,1) = \\{0,1\\} = B\\) \\(Dtran[A,b] = \\epsilon-closure(0) = A\\) \\(Dtran[B,a] = \\epsilon-closure(0,1,2) = \\{0,1,2\\} = C\\) \\(Dtran[B,b] = \\epsilon-closure(0,1) = B\\) \\(Dtran[C,a] = \\epsilon-closure(0,1,2) = C\\) \\(Dtran[C,b] = \\epsilon-closure(0,1,2,3) = D\\) \\(Dtran[D,a] = \\epsilon-closure(0,1,2) = C\\) \\(Dtran[D,b] = \\epsilon-closure(0,1,2,4) = D\\) NFA DFA a b {0} A B A {0,1} B C B {0,1,2} C C D {0,1,2,3} D C D","title":"\u539a\u4e66 3.7.1"},{"location":"Compiler-Principle/2/#421","text":"\\(S \\rightarrow SS* \\rightarrow SS+S* \\rightarrow aS+S* \\rightarrow aa+S* \\rightarrow aa+a*\\) \\(S \\rightarrow SS* \\rightarrow Sa* \\rightarrow SS+a* \\rightarrow Sa+a* \\rightarrow aa+a*\\) \u5982\u4e0b\u56fe \u7565 \u6240\u6709\u52a0\u6cd5\u548c\u4e58\u6cd5\u6df7\u5408\u7684a\u7684\u540e\u7f00\u8868\u8fbe\u5f0f\u96c6\u5408","title":"4.2.1"},{"location":"Compiler-Principle/3/","text":"\u7f16\u8bd1\u539f\u7406 \u7b2c\u4e09\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf \u00b6 4.4.1 \u00b6 \u65e0\u5de6\u516c\u56e0\u5b50\uff0c\u6d88\u9664\u5de6\u9012\u5f52\u540e\u5f97\u5230: bexpr \\(\\rightarrow\\) bterm bexpr' bexpr' \\(\\rightarrow\\) or bterm bexpr' | \\(\\epsilon\\) bterm \\(\\rightarrow\\) bfactor bterm' bterm' \\(\\rightarrow\\) and bfactor bterm' | \\(\\epsilon\\) bfactor \\(\\rightarrow\\) not bfactor | (bexpr) | true | false First(bexpr) = First(bterm) = First(bfactor) = { not ,(, true , false } First(bexpr') = { or , \\(\\epsilon\\) } First(bterm) = { and , \\(\\epsilon\\) } Follow(bexpr) = Follow(bexpr') = { ), $ } Follow(bterm) = Follow(bterm') = { or, $ } Follow(bfactor) = { and, $ } \u9884\u6d4b\u5206\u6790\u8868\uff1a \u975e\u7ec8\u7ed3\u7b26\u53f7 \u8f93\u5165\u7b26\u53f7 and or not ( ) true false $ bexpr bexpr -> bterm bexpr' bexpr -> bterm bexpr' bexpr -> bterm bexpr' bexpr -> bterm bexpr' bexpr' bexpr' -> or bterm bexpr' bexpr' -> \u03b5 bexpr' -> \u03b5 bterm bterm -> bfactor bterm' bterm -> bfactor bterm' bterm -> bfactor bterm' bterm -> bfactor bterm' bterm' bterm' -> and bfactor bterm' bterm' -> \u03b5 bterm' -> \u03b5 bfactor bfactor -> not bfactor bfactor -> (bexpr) bfactor -> true bfactor -> false 4.4.4 \u00b6 First(S) = { (, \\(\\epsilon\\) } FollowS(S) = { ), $ } 4.4.5 \u00b6 \u5bf9\u4e8e\u8fd9\u4e2a\u5e26\u56de\u6eaf\u7684\u9012\u5f52\u4e0b\u964d\u5206\u6790\u5668\uff0c \u5b83\u6bcf\u4e00\u6b21\u53d1\u73b0\u9519\u8bef\u540e\u56de\u6eaf\u6240\u6d88\u53bb\u7684a\u7684\u6570\u91cf\u4e3a2,4,8..... \u5373 \\(2^n\\) \uff0c\u90a3\u4e48\u53ea\u6709\u5728a\u7684\u4e2a\u6570\u4e3a \\(\\{a^{2^n} | n\u22651\\}\\) \u65f6, \u5047\u8bbe\u4e3ak\uff0c\u5219\u4ed6\u7684\u9884\u6d4ba\u7684\u4e2a\u6570\u4e3a \\(2^k - 2^i,i=1,2,3...\\) , \u5f53i\u7b49\u4e8ek-1\u65f6\u5339\u914d\u6210\u529f\u3002 \u800c\u5bf9\u4e8e\u516d\u6765\u8bf4\uff0c\u53ea\u67093\u624d\u80fd\u5339\u914d\uff0c\u4f46\u662f\u4ed6\u4e0d\u4f1a\u7ecf\u5386\u8fd9\u4e2a\u60c5\u51b5\u3002 \u4ed6\u8bc6\u522b \\(\\{a^{2^n} | n\u22651\\}\\) \u7684\u60c5\u51b5 4.5.2 \u00b6 S \\(\\Rightarrow\\) S S + \\(\\Rightarrow\\) S S S + + \\(\\Rightarrow\\) S S a + + \\(\\Rightarrow\\) S S S * a + + \\(~~~ \\Rightarrow\\) S S a * a + + \\(\\Rightarrow\\) S a a * a + + \\(\\Rightarrow\\) a a a * a + +","title":"\u4f5c\u4e1a3"},{"location":"Compiler-Principle/3/#_1","text":"","title":"\u7f16\u8bd1\u539f\u7406 \u7b2c\u4e09\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/3/#151220129","text":"","title":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf"},{"location":"Compiler-Principle/3/#441","text":"\u65e0\u5de6\u516c\u56e0\u5b50\uff0c\u6d88\u9664\u5de6\u9012\u5f52\u540e\u5f97\u5230: bexpr \\(\\rightarrow\\) bterm bexpr' bexpr' \\(\\rightarrow\\) or bterm bexpr' | \\(\\epsilon\\) bterm \\(\\rightarrow\\) bfactor bterm' bterm' \\(\\rightarrow\\) and bfactor bterm' | \\(\\epsilon\\) bfactor \\(\\rightarrow\\) not bfactor | (bexpr) | true | false First(bexpr) = First(bterm) = First(bfactor) = { not ,(, true , false } First(bexpr') = { or , \\(\\epsilon\\) } First(bterm) = { and , \\(\\epsilon\\) } Follow(bexpr) = Follow(bexpr') = { ), $ } Follow(bterm) = Follow(bterm') = { or, $ } Follow(bfactor) = { and, $ } \u9884\u6d4b\u5206\u6790\u8868\uff1a \u975e\u7ec8\u7ed3\u7b26\u53f7 \u8f93\u5165\u7b26\u53f7 and or not ( ) true false $ bexpr bexpr -> bterm bexpr' bexpr -> bterm bexpr' bexpr -> bterm bexpr' bexpr -> bterm bexpr' bexpr' bexpr' -> or bterm bexpr' bexpr' -> \u03b5 bexpr' -> \u03b5 bterm bterm -> bfactor bterm' bterm -> bfactor bterm' bterm -> bfactor bterm' bterm -> bfactor bterm' bterm' bterm' -> and bfactor bterm' bterm' -> \u03b5 bterm' -> \u03b5 bfactor bfactor -> not bfactor bfactor -> (bexpr) bfactor -> true bfactor -> false","title":"4.4.1"},{"location":"Compiler-Principle/3/#444","text":"First(S) = { (, \\(\\epsilon\\) } FollowS(S) = { ), $ }","title":"4.4.4"},{"location":"Compiler-Principle/3/#445","text":"\u5bf9\u4e8e\u8fd9\u4e2a\u5e26\u56de\u6eaf\u7684\u9012\u5f52\u4e0b\u964d\u5206\u6790\u5668\uff0c \u5b83\u6bcf\u4e00\u6b21\u53d1\u73b0\u9519\u8bef\u540e\u56de\u6eaf\u6240\u6d88\u53bb\u7684a\u7684\u6570\u91cf\u4e3a2,4,8..... \u5373 \\(2^n\\) \uff0c\u90a3\u4e48\u53ea\u6709\u5728a\u7684\u4e2a\u6570\u4e3a \\(\\{a^{2^n} | n\u22651\\}\\) \u65f6, \u5047\u8bbe\u4e3ak\uff0c\u5219\u4ed6\u7684\u9884\u6d4ba\u7684\u4e2a\u6570\u4e3a \\(2^k - 2^i,i=1,2,3...\\) , \u5f53i\u7b49\u4e8ek-1\u65f6\u5339\u914d\u6210\u529f\u3002 \u800c\u5bf9\u4e8e\u516d\u6765\u8bf4\uff0c\u53ea\u67093\u624d\u80fd\u5339\u914d\uff0c\u4f46\u662f\u4ed6\u4e0d\u4f1a\u7ecf\u5386\u8fd9\u4e2a\u60c5\u51b5\u3002 \u4ed6\u8bc6\u522b \\(\\{a^{2^n} | n\u22651\\}\\) \u7684\u60c5\u51b5","title":"4.4.5"},{"location":"Compiler-Principle/3/#452","text":"S \\(\\Rightarrow\\) S S + \\(\\Rightarrow\\) S S S + + \\(\\Rightarrow\\) S S a + + \\(\\Rightarrow\\) S S S * a + + \\(~~~ \\Rightarrow\\) S S a * a + + \\(\\Rightarrow\\) S a a * a + + \\(\\Rightarrow\\) a a a * a + +","title":"4.5.2"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf \u00b6 \u539a\u4e66 3.3.2 \u00b6 (3) \u7531a\u4e0eb\u7ec4\u6210\u7684\uff0c\u540e\u7f00\u4e3aaaa,aab,aba,abb\u7684\u4e32 \u539a\u4e66 3.3.5 \u00b6 \u5b9a\u4e49\u03b2\u4e3a\u6240\u6709\u975e\u5143\u97f3\u5c0f\u5199\u5b57\u6bcd\u7684\u96c6\u5408\uff0c\u5219\u5176\u6b63\u5219\u8868\u8fbe\u5f0f\u4e3a \\(\u03b2^* a(a\u2502\u03b2)^* e(e\u2502\u03b2)^* i(i\u2502\u03b2)^* o(o\u2502\u03b2)^* u(u\u2502\u03b2)^*\\) \u539a\u4e66 3.4.1 \u00b6 \u539a\u4e66 3.6.4 \u00b6 0->1->0->1->2->3 0->3->0->1->2->3 \u63a5\u53d7 \u539a\u4e66 3.6.5 \u00b6 (2) \u72b6\u6001 a b \\(\\varepsilon\\) 0 {1} \\(\\phi\\) {3} 1 \\(\\phi\\) {2} {0} 2 \\(\\phi\\) {3} {1} 3 {0} \\(\\phi\\) {2} \u539a\u4e66 3.7.1 \u00b6 (3)\u4e00\u4e2a\u72b6\u6001 NFA\u72b6\u6001 DFA\u72b6\u6001 a b {0,1,2,3} A A A","title":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#151220129","text":"","title":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#332","text":"(3) \u7531a\u4e0eb\u7ec4\u6210\u7684\uff0c\u540e\u7f00\u4e3aaaa,aab,aba,abb\u7684\u4e32","title":"\u539a\u4e66 3.3.2"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#335","text":"\u5b9a\u4e49\u03b2\u4e3a\u6240\u6709\u975e\u5143\u97f3\u5c0f\u5199\u5b57\u6bcd\u7684\u96c6\u5408\uff0c\u5219\u5176\u6b63\u5219\u8868\u8fbe\u5f0f\u4e3a \\(\u03b2^* a(a\u2502\u03b2)^* e(e\u2502\u03b2)^* i(i\u2502\u03b2)^* o(o\u2502\u03b2)^* u(u\u2502\u03b2)^*\\)","title":"\u539a\u4e66 3.3.5"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#341","text":"","title":"\u539a\u4e66 3.4.1"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#364","text":"0->1->0->1->2->3 0->3->0->1->2->3 \u63a5\u53d7","title":"\u539a\u4e66 3.6.4"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#365","text":"(2) \u72b6\u6001 a b \\(\\varepsilon\\) 0 {1} \\(\\phi\\) {3} 1 \\(\\phi\\) {2} {0} 2 \\(\\phi\\) {3} {1} 3 {0} \\(\\phi\\) {2}","title":"\u539a\u4e66 3.6.5"},{"location":"Compiler-Principle/3_%E7%AC%AC%E4%B8%89%E7%AB%A0%E4%BD%9C%E4%B8%9A/#371","text":"(3)\u4e00\u4e2a\u72b6\u6001 NFA\u72b6\u6001 DFA\u72b6\u6001 a b {0,1,2,3} A A A","title":"\u539a\u4e66 3.7.1"},{"location":"Compiler-Principle/4/","text":"[\u7f16\u8bd1\u539f\u7406] \u7b2c\u56db\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 18805156360@163.com 4.5.3 \u00b6 \u6808 \u8f93\u5165 \u53e5\u67c4 \u52a8\u4f5c $ aaa*a++$ \u79fb\u5165 $a aa*a++$ a \u89c4\u7ea6: S -> a $S aa*a++$ \u79fb\u5165 $Sa a*a++$ a \u89c4\u7ea6: S -> a $SS a*a++$ \u79fb\u5165 $SSa *a++$ a \u89c4\u7ea6: S -> a $SSS *a++$ \u79fb\u5165 $SSS* a++$ SS* \u89c4\u7ea6: S -> SS* $SS a++$ \u79fb\u5165 $SSa ++$ a \u89c4\u7ea6: S -> a $SSS ++$ \u79fb\u5165 $SSS+ +$ SS+ \u89c4\u7ea6: S -> SS+ $SS +$ \u79fb\u5165 $SS+ $ SS+ \u89c4\u7ea6: S -> SS+ $S $ \u63a5\u53d7 4.6.2 \u00b6 Follow(S) = {+ , *, $ , a} GOTO\u51fd\u6570\u8868 + * $ a S \\(I_0\\) \\(I_2\\) \\(I_1\\) \\(I_1\\) ACCEPT \\(I_2\\) \\(I_3\\) \\(I_2\\) \\(I_3\\) \\(I_4\\) \\(I_5\\) \\(I_2\\) \\(I_3\\) \\(I_4\\) \\(I_5\\) \u4e0b\u9762\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7 1. S -> SS+ 2. S -> SS* 3. S -> a \u5f97\u5230SLR\u8bed\u6cd5\u5206\u6790\u8868: \u56e0\u4e3a\u65e0\u51b2\u7a81\uff0c\u6240\u4ee5\u662fSLR\u6587\u6cd5\u3002 4.6.3 \u00b6 \u6808 \u7b26\u53f7 \u8f93\u5165 \u52a8\u4f5c 0 aa*a+$ \u79fb\u5165 02 a a*a+$ \u6309\u7167S->a\u5f52\u7ea6 01 S a*a+$ \u79fb\u5165 012 Sa *a+$ \u6309\u7167S->a\u5f52\u7ea6 013 SS *a+$ \u79fb\u5165 0135 SS* a+$ \u6309\u7167S->SS*\u5f52\u7ea6 01 S a+$ \u79fb\u5165 012 Sa +$ \u6309\u7167S->a\u5f52\u7ea6 013 SS +$ \u79fb\u5165 0134 SS+ $ \u6309\u7167S->SS+\u5f52\u7ea6 01 S $ \u63a5\u53d7 4.6.6 \u00b6 \u8be5\u6587\u6cd5\u4e0d\u662f LL(1) \u7684 S -> SA \u548c S -> A \u5747\u80fd\u63a8\u5bfc\u51fa\u4ee5 a \u5f00\u5934\u7684\u4e32\uff0c\u6240\u4ee5\u4e0d\u662f LL(1) \u7684 \u8be5\u6587\u6cd5\u662f SLR(1) \u7684 \u8be5\u6587\u6cd5\u751f\u6210\u7684\u8bed\u6cd5\u5206\u6790\u8868\u662f\u6ca1\u6709\u51b2\u7a81\u7684","title":"\u4f5c\u4e1a4"},{"location":"Compiler-Principle/4/#_1","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 18805156360@163.com","title":"[\u7f16\u8bd1\u539f\u7406] \u7b2c\u56db\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/4/#453","text":"\u6808 \u8f93\u5165 \u53e5\u67c4 \u52a8\u4f5c $ aaa*a++$ \u79fb\u5165 $a aa*a++$ a \u89c4\u7ea6: S -> a $S aa*a++$ \u79fb\u5165 $Sa a*a++$ a \u89c4\u7ea6: S -> a $SS a*a++$ \u79fb\u5165 $SSa *a++$ a \u89c4\u7ea6: S -> a $SSS *a++$ \u79fb\u5165 $SSS* a++$ SS* \u89c4\u7ea6: S -> SS* $SS a++$ \u79fb\u5165 $SSa ++$ a \u89c4\u7ea6: S -> a $SSS ++$ \u79fb\u5165 $SSS+ +$ SS+ \u89c4\u7ea6: S -> SS+ $SS +$ \u79fb\u5165 $SS+ $ SS+ \u89c4\u7ea6: S -> SS+ $S $ \u63a5\u53d7","title":"4.5.3"},{"location":"Compiler-Principle/4/#462","text":"Follow(S) = {+ , *, $ , a} GOTO\u51fd\u6570\u8868 + * $ a S \\(I_0\\) \\(I_2\\) \\(I_1\\) \\(I_1\\) ACCEPT \\(I_2\\) \\(I_3\\) \\(I_2\\) \\(I_3\\) \\(I_4\\) \\(I_5\\) \\(I_2\\) \\(I_3\\) \\(I_4\\) \\(I_5\\) \u4e0b\u9762\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7 1. S -> SS+ 2. S -> SS* 3. S -> a \u5f97\u5230SLR\u8bed\u6cd5\u5206\u6790\u8868: \u56e0\u4e3a\u65e0\u51b2\u7a81\uff0c\u6240\u4ee5\u662fSLR\u6587\u6cd5\u3002","title":"4.6.2"},{"location":"Compiler-Principle/4/#463","text":"\u6808 \u7b26\u53f7 \u8f93\u5165 \u52a8\u4f5c 0 aa*a+$ \u79fb\u5165 02 a a*a+$ \u6309\u7167S->a\u5f52\u7ea6 01 S a*a+$ \u79fb\u5165 012 Sa *a+$ \u6309\u7167S->a\u5f52\u7ea6 013 SS *a+$ \u79fb\u5165 0135 SS* a+$ \u6309\u7167S->SS*\u5f52\u7ea6 01 S a+$ \u79fb\u5165 012 Sa +$ \u6309\u7167S->a\u5f52\u7ea6 013 SS +$ \u79fb\u5165 0134 SS+ $ \u6309\u7167S->SS+\u5f52\u7ea6 01 S $ \u63a5\u53d7","title":"4.6.3"},{"location":"Compiler-Principle/4/#466","text":"\u8be5\u6587\u6cd5\u4e0d\u662f LL(1) \u7684 S -> SA \u548c S -> A \u5747\u80fd\u63a8\u5bfc\u51fa\u4ee5 a \u5f00\u5934\u7684\u4e32\uff0c\u6240\u4ee5\u4e0d\u662f LL(1) \u7684 \u8be5\u6587\u6cd5\u662f SLR(1) \u7684 \u8be5\u6587\u6cd5\u751f\u6210\u7684\u8bed\u6cd5\u5206\u6790\u8868\u662f\u6ca1\u6709\u51b2\u7a81\u7684","title":"4.6.6"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/","text":"\u7b2c\u56db\u7ae0\u4f5c\u4e1a \u00b6 4.2.1 \u00b6 \\(S \\rightarrow SS* \\rightarrow SS+S* \\rightarrow aS+S* \\rightarrow aa+S* \\rightarrow aa+a*\\) \\(S \\rightarrow SS* \\rightarrow Sa* \\rightarrow SS+a* \\rightarrow Sa+a* \\rightarrow aa+a*\\) \u5982\u4e0b\u56fe \u7565 \u6240\u6709\u7684\u540e\u7f00\u8868\u8fbe\u5f0f\u7684\u96c6\u5408\u7ec4\u6210\u7684\u52a0\u6cd5\u548c\u4e58\u6cd5 4.4.1 \u00b6 (5) \\(S\\rightarrow (L) | a\\) \u4ee5\u53ca \\(L\\rightarrow L,S | S\\) \u63d0\u53d6\u5de6\u516c\u56e0\u5b50(\u65e0) \u6d88\u9664\u5de6\u9012\u5f52\uff08\u4ec5\u6709 \\(L\\rightarrow L,S|S\\) \u8fd9\u4e00\u5904\u7acb\u5373\u5de6\u9012\u5f52\uff09 \\(S\\rightarrow (L) | a\\) \\(L\\rightarrow SL'\\) \\(L'\\rightarrow ,SL'|\\epsilon\\) \u8ba1\u7b97First\u548cFollow First(S) = { ( , a } First(L) = { ( , a } First(L') = { \uff0c, \u03b5 } Follow(S) = { $ , \uff0c, ) } Follow(L) = { ) } Follow(L')= { ) } \u6700\u7ec8\u5f97\u5230\u9884\u6d4b\u5206\u6790\u8868\uff1a \u975e\u7ec8\u7ed3\u7b26\u53f7 \u8f93\u5165\u7b26\u53f7 ( ) , a $ S $S \\rightarrow (L)$ $S \\rightarrow a$ S $L \\rightarrow SL'$ $L \\rightarrow SL'$ L' $L' \\rightarrow \\epsilon$ $L' \\rightarrow ,SL'$ 4.4.2 \u00b6 \u63d0\u53d6\u5de6\u516c\u56e0\u5b50 \\(S \\rightarrow SSA | a\\) \\(A \\rightarrow + | *\\) \u6d88\u9664\u5de6\u9012\u5f52 i = 1 S -> aB B -> SAB | \u03b5 A -> + | * i = 2 j = 1 S -> aB B -> aBAB | \u03b5 A -> + | * \u9884\u6d4b\u5206\u6790\u8868 \u975e\u7ec8\u7ed3\u7b26\u53f7 \u8f93\u5165\u7b26\u53f7 + * a $ S S -> aB A A -> + A -> * B B -> \u03b5 B -> \u03b5 B -> aBAB B -> \u03b5 4.4.3 \u00b6 \\(First(S) = \\{a\\}\\) \\(Follow(S) = \\{a, +, *, \\$\\} \\) 4.4.5 \u00b6 \u5bf9\u4e8e\u8fd9\u4e2a\u5e26\u56de\u6eaf\u7684\u9012\u5f52\u4e0b\u964d\u5206\u6790\u5668\uff0c \u5b83\u6bcf\u4e00\u6b21\u53d1\u73b0\u9519\u8bef\u540e\u56de\u6eaf\u6240\u6d88\u53bb\u7684a\u7684\u6570\u91cf\u4e3a2,4,8..... \u5373 \\(2^n\\) \uff0c\u90a3\u4e48\u53ea\u6709\u5728a\u7684\u4e2a\u6570\u4e3a \\(\\{a^{2^n} | n\u22651\\}\\) \u65f6, \u5047\u8bbe\u4e3ak\uff0c\u5219\u4ed6\u7684\u9884\u6d4ba\u7684\u4e2a\u6570\u4e3a \\(2^k - 2^i,i=1,2,3...\\) , \u5f53i\u7b49\u4e8ek-1\u65f6\u5339\u914d\u6210\u529f\u3002 \u800c\u5bf9\u4e8e\u516d\u6765\u8bf4\uff0c\u53ea\u67093\u624d\u80fd\u5339\u914d\uff0c\u4f46\u662f\u4ed6\u4e0d\u4f1a\u7ecf\u5386\u8fd9\u4e2a\u60c5\u51b5\u3002 \u4ed6\u8bc6\u522b \\(\\{a^{2^n} | n\u22651\\}\\) \u7684\u60c5\u51b5 4.5.2 \u00b6 S -> SS+ -> Sa+ -> SS*a+ ->Sa*a+ -> SS+a*a+ \u56e0\u6b64\u53e5\u67c4\u4e3aSS+","title":"\u7b2c\u56db\u7ae0\u4f5c\u4e1a"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#_1","text":"","title":"\u7b2c\u56db\u7ae0\u4f5c\u4e1a"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#421","text":"\\(S \\rightarrow SS* \\rightarrow SS+S* \\rightarrow aS+S* \\rightarrow aa+S* \\rightarrow aa+a*\\) \\(S \\rightarrow SS* \\rightarrow Sa* \\rightarrow SS+a* \\rightarrow Sa+a* \\rightarrow aa+a*\\) \u5982\u4e0b\u56fe \u7565 \u6240\u6709\u7684\u540e\u7f00\u8868\u8fbe\u5f0f\u7684\u96c6\u5408\u7ec4\u6210\u7684\u52a0\u6cd5\u548c\u4e58\u6cd5","title":"4.2.1"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#441","text":"(5) \\(S\\rightarrow (L) | a\\) \u4ee5\u53ca \\(L\\rightarrow L,S | S\\) \u63d0\u53d6\u5de6\u516c\u56e0\u5b50(\u65e0) \u6d88\u9664\u5de6\u9012\u5f52\uff08\u4ec5\u6709 \\(L\\rightarrow L,S|S\\) \u8fd9\u4e00\u5904\u7acb\u5373\u5de6\u9012\u5f52\uff09 \\(S\\rightarrow (L) | a\\) \\(L\\rightarrow SL'\\) \\(L'\\rightarrow ,SL'|\\epsilon\\) \u8ba1\u7b97First\u548cFollow First(S) = { ( , a } First(L) = { ( , a } First(L') = { \uff0c, \u03b5 } Follow(S) = { $ , \uff0c, ) } Follow(L) = { ) } Follow(L')= { ) } \u6700\u7ec8\u5f97\u5230\u9884\u6d4b\u5206\u6790\u8868\uff1a \u975e\u7ec8\u7ed3\u7b26\u53f7 \u8f93\u5165\u7b26\u53f7 ( ) , a $ S $S \\rightarrow (L)$ $S \\rightarrow a$ S $L \\rightarrow SL'$ $L \\rightarrow SL'$ L' $L' \\rightarrow \\epsilon$ $L' \\rightarrow ,SL'$","title":"4.4.1"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#442","text":"\u63d0\u53d6\u5de6\u516c\u56e0\u5b50 \\(S \\rightarrow SSA | a\\) \\(A \\rightarrow + | *\\) \u6d88\u9664\u5de6\u9012\u5f52 i = 1 S -> aB B -> SAB | \u03b5 A -> + | * i = 2 j = 1 S -> aB B -> aBAB | \u03b5 A -> + | * \u9884\u6d4b\u5206\u6790\u8868 \u975e\u7ec8\u7ed3\u7b26\u53f7 \u8f93\u5165\u7b26\u53f7 + * a $ S S -> aB A A -> + A -> * B B -> \u03b5 B -> \u03b5 B -> aBAB B -> \u03b5","title":"4.4.2"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#443","text":"\\(First(S) = \\{a\\}\\) \\(Follow(S) = \\{a, +, *, \\$\\} \\)","title":"4.4.3"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#445","text":"\u5bf9\u4e8e\u8fd9\u4e2a\u5e26\u56de\u6eaf\u7684\u9012\u5f52\u4e0b\u964d\u5206\u6790\u5668\uff0c \u5b83\u6bcf\u4e00\u6b21\u53d1\u73b0\u9519\u8bef\u540e\u56de\u6eaf\u6240\u6d88\u53bb\u7684a\u7684\u6570\u91cf\u4e3a2,4,8..... \u5373 \\(2^n\\) \uff0c\u90a3\u4e48\u53ea\u6709\u5728a\u7684\u4e2a\u6570\u4e3a \\(\\{a^{2^n} | n\u22651\\}\\) \u65f6, \u5047\u8bbe\u4e3ak\uff0c\u5219\u4ed6\u7684\u9884\u6d4ba\u7684\u4e2a\u6570\u4e3a \\(2^k - 2^i,i=1,2,3...\\) , \u5f53i\u7b49\u4e8ek-1\u65f6\u5339\u914d\u6210\u529f\u3002 \u800c\u5bf9\u4e8e\u516d\u6765\u8bf4\uff0c\u53ea\u67093\u624d\u80fd\u5339\u914d\uff0c\u4f46\u662f\u4ed6\u4e0d\u4f1a\u7ecf\u5386\u8fd9\u4e2a\u60c5\u51b5\u3002 \u4ed6\u8bc6\u522b \\(\\{a^{2^n} | n\u22651\\}\\) \u7684\u60c5\u51b5","title":"4.4.5"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%281%29/#452","text":"S -> SS+ -> Sa+ -> SS*a+ ->Sa*a+ -> SS+a*a+ \u56e0\u6b64\u53e5\u67c4\u4e3aSS+","title":"4.5.2"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/","text":"\u7f16\u8bd1\u539f\u7406\u7b2c\u56db\u7ae0\u4f5c\u4e1a(2) \u00b6 \u8ba1\u79d1 \u5434\u653f\u4ebf \u00b6 \u7f16\u8bd1\u539f\u7406\u7b2c\u56db\u7ae0\u4f5c\u4e1a(2) 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 4.6.2 4.6.3 4.6.6 4.7.1 2 \u00b6 \u589e\u5e7f\u6587\u6cd5: (0) \\(S' \\rightarrow S\\) (1) \\(S \\rightarrow S S +\\) (2) \\(B \\rightarrow S S *\\) (3) \\(B \\rightarrow a\\) SLR\u9879\u96c6\u5982\u4e0b: \\(I_0:S' \\rightarrow \\cdot S, S \\rightarrow \\cdot SS+, S \\rightarrow \\cdot SS*,S \\rightarrow \\cdot a\\) \\(I_1:S' \\rightarrow a \\cdot\\) \\(I_2:S' \\rightarrow S \\cdot , S \\rightarrow S \\cdot S+, S \\rightarrow S \\cdot S*,S \\rightarrow \\cdot SS+, S \\rightarrow \\cdot SS*,S \\rightarrow \\cdot a\\) \\(I_3:S' \\rightarrow SS \\cdot +, S \\rightarrow SS \\cdot *, S \\rightarrow S \\cdot S+,\\) \\(\\ \\ \\ \\ \\ \\ \\ S \\rightarrow S \\cdot S*,S \\rightarrow \\cdot SS+, S \\rightarrow \\cdot SS*,S \\rightarrow \\cdot a\\) \\(I_4:S' \\rightarrow SS+ \\cdot\\) \\(I_5:S' \\rightarrow SS* \\cdot\\) GOTO \u51fd\u6570\u5982\u4e0b: \\(GOTO(I_0,a)=I_1\\) , \\(GOTO(I_0,S)=I_2\\) \\(GOTO(I_2,a)=I_1\\) , \\(GOTO(I_2,S)=I_3\\) , \\(GOTO(I_2,\\) $ \\()=accept\\) \\(GOTO(I_3,a)=I_1\\) , \\(GOTO(I_3,S)=I_3\\) \\(GOTO(I_3,+)=I_4\\) , \\(GOTO(I_3,*)=I_5\\) \u8bed\u6cd5\u5206\u6790\u8868\u5982\u4e0b\uff1a \u72b6\u6001 ACTION GOTO a + * $ S 0 S1 2 1 r3 r3 r3 r3 2 S1 accept 3 3 S1 S4 S5 3 4 r1 r1 r1 r1 5 r2 r2 r2 r2 \u65e0\u51b2\u7a81\uff0c\u8fd9\u663e\u7136\u662f\u4e00\u4e2a SLR \u6587\u6cd5 3 \u00b6 \u5e8f\u53f7 \u6808 \u7b26\u53f7 \u8f93\u5165 \u52a8\u4f5c (1) 0 aa*a+$ \u79fb\u5165 (2) 01 a a*a+$ \u6309S->a\u89c4\u7ea6 (3) 02 S a*a+$ \u79fb\u5165 (4) 021 Sa *a+$ \u6309S->a\u89c4\u7ea6 (5) 023 SS *a+$ \u79fb\u5165 (6) 0235 SS* a+$ \u6309S->SS*\u89c4\u7ea6 (7) 02 S a+$ \u79fb\u5165 (8) 021 Sa +$ \u6309S->a\u89c4\u7ea6 (9) 023 SS +$ \u79fb\u5165 (10) 0234 SS+ $ \u6309S->SS+\u89c4\u7ea6 (11) 02 S $ \u63a5\u53d7 6 \u00b6 \u56e0\u4e3aFirst(SA) = First(A) = {a}\uff0c\u6240\u4ee5\u8be5\u6587\u6cd5\u4e0d\u662fLL(1)\u7684\u3002 \u4e0b\u8bc1\u8be5\u6587\u6cd5\u662fSLR(1)\u7684\uff1a \u589e\u5e7f\u6587\u6cd5\uff1a (0) \\(S' \\rightarrow S\\) (1) \\(S \\rightarrow SA\\) (2) \\(S \\rightarrow A\\) (3) \\(A \\rightarrow a\\) SLR\u9879\u96c6: \\(I_0:S' \\rightarrow \\cdot S , S \\rightarrow \\cdot SA,S \\rightarrow \\cdot A , A \\rightarrow \\cdot a\\) \\(I_1:A \\rightarrow a \\cdot\\) \\(I_2:S \\rightarrow A \\cdot\\) \\(I_3:S' \\rightarrow S \\cdot , S \\rightarrow S \\cdot A , A \\rightarrow \\cdot a\\) \\(I_4:S \\rightarrow SA \\cdot\\) \u8bed\u6cd5\u5206\u6790\u8868: \u72b6\u6001 ACTION GOTO a $ S A 0 S1 S2 S3 1 r3 r3 2 r2 r2 3 S! acc S4 4 r1 r1 \u56e0\u4e3a\u6ca1\u6709\u91cd\u590d\u7684\u51b2\u7a81\u9879\uff0c\u6545\u8be5\u6587\u6cd5\u4e3aSLR\uff081\uff09\u7684\u3002 1 \u00b6 \u89c4\u8303LR\u9879\u96c6\u65cf I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> a\u00b7 , $], [S' -> a\u00b7 , a] I2: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +] I4: [S' -> SS\u00b7+, $], [S' -> SS\u00b7+, a] [S' -> SS\u00b7*, $], [S' -> SS\u00b7*, a] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I5: [S' -> SS+\u00b7, $], [S' -> SS+\u00b7, a] I6: [S' -> SS*\u00b7, $], [S' -> SS*\u00b7, a] I7: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, +] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I8: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +] I9: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +] LALR\u9879\u96c6\u65cf: I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I2: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +], [S' -> SS\u00b7+, $] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, $] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +], [S' -> a\u00b7 , $] I4: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +], [S' -> SS+\u00b7, $] I5: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +], [S' -> SS*\u00b7, $]","title":"\u7f16\u8bd1\u539f\u7406\u7b2c\u56db\u7ae0\u4f5c\u4e1a(2)"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/#2","text":"","title":"\u7f16\u8bd1\u539f\u7406\u7b2c\u56db\u7ae0\u4f5c\u4e1a(2)"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/#_1","text":"\u7f16\u8bd1\u539f\u7406\u7b2c\u56db\u7ae0\u4f5c\u4e1a(2) 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 4.6.2 4.6.3 4.6.6 4.7.1","title":"\u8ba1\u79d1 \u5434\u653f\u4ebf"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/#2_1","text":"\u589e\u5e7f\u6587\u6cd5: (0) \\(S' \\rightarrow S\\) (1) \\(S \\rightarrow S S +\\) (2) \\(B \\rightarrow S S *\\) (3) \\(B \\rightarrow a\\) SLR\u9879\u96c6\u5982\u4e0b: \\(I_0:S' \\rightarrow \\cdot S, S \\rightarrow \\cdot SS+, S \\rightarrow \\cdot SS*,S \\rightarrow \\cdot a\\) \\(I_1:S' \\rightarrow a \\cdot\\) \\(I_2:S' \\rightarrow S \\cdot , S \\rightarrow S \\cdot S+, S \\rightarrow S \\cdot S*,S \\rightarrow \\cdot SS+, S \\rightarrow \\cdot SS*,S \\rightarrow \\cdot a\\) \\(I_3:S' \\rightarrow SS \\cdot +, S \\rightarrow SS \\cdot *, S \\rightarrow S \\cdot S+,\\) \\(\\ \\ \\ \\ \\ \\ \\ S \\rightarrow S \\cdot S*,S \\rightarrow \\cdot SS+, S \\rightarrow \\cdot SS*,S \\rightarrow \\cdot a\\) \\(I_4:S' \\rightarrow SS+ \\cdot\\) \\(I_5:S' \\rightarrow SS* \\cdot\\) GOTO \u51fd\u6570\u5982\u4e0b: \\(GOTO(I_0,a)=I_1\\) , \\(GOTO(I_0,S)=I_2\\) \\(GOTO(I_2,a)=I_1\\) , \\(GOTO(I_2,S)=I_3\\) , \\(GOTO(I_2,\\) $ \\()=accept\\) \\(GOTO(I_3,a)=I_1\\) , \\(GOTO(I_3,S)=I_3\\) \\(GOTO(I_3,+)=I_4\\) , \\(GOTO(I_3,*)=I_5\\) \u8bed\u6cd5\u5206\u6790\u8868\u5982\u4e0b\uff1a \u72b6\u6001 ACTION GOTO a + * $ S 0 S1 2 1 r3 r3 r3 r3 2 S1 accept 3 3 S1 S4 S5 3 4 r1 r1 r1 r1 5 r2 r2 r2 r2 \u65e0\u51b2\u7a81\uff0c\u8fd9\u663e\u7136\u662f\u4e00\u4e2a SLR \u6587\u6cd5","title":"2"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/#3","text":"\u5e8f\u53f7 \u6808 \u7b26\u53f7 \u8f93\u5165 \u52a8\u4f5c (1) 0 aa*a+$ \u79fb\u5165 (2) 01 a a*a+$ \u6309S->a\u89c4\u7ea6 (3) 02 S a*a+$ \u79fb\u5165 (4) 021 Sa *a+$ \u6309S->a\u89c4\u7ea6 (5) 023 SS *a+$ \u79fb\u5165 (6) 0235 SS* a+$ \u6309S->SS*\u89c4\u7ea6 (7) 02 S a+$ \u79fb\u5165 (8) 021 Sa +$ \u6309S->a\u89c4\u7ea6 (9) 023 SS +$ \u79fb\u5165 (10) 0234 SS+ $ \u6309S->SS+\u89c4\u7ea6 (11) 02 S $ \u63a5\u53d7","title":"3"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/#6","text":"\u56e0\u4e3aFirst(SA) = First(A) = {a}\uff0c\u6240\u4ee5\u8be5\u6587\u6cd5\u4e0d\u662fLL(1)\u7684\u3002 \u4e0b\u8bc1\u8be5\u6587\u6cd5\u662fSLR(1)\u7684\uff1a \u589e\u5e7f\u6587\u6cd5\uff1a (0) \\(S' \\rightarrow S\\) (1) \\(S \\rightarrow SA\\) (2) \\(S \\rightarrow A\\) (3) \\(A \\rightarrow a\\) SLR\u9879\u96c6: \\(I_0:S' \\rightarrow \\cdot S , S \\rightarrow \\cdot SA,S \\rightarrow \\cdot A , A \\rightarrow \\cdot a\\) \\(I_1:A \\rightarrow a \\cdot\\) \\(I_2:S \\rightarrow A \\cdot\\) \\(I_3:S' \\rightarrow S \\cdot , S \\rightarrow S \\cdot A , A \\rightarrow \\cdot a\\) \\(I_4:S \\rightarrow SA \\cdot\\) \u8bed\u6cd5\u5206\u6790\u8868: \u72b6\u6001 ACTION GOTO a $ S A 0 S1 S2 S3 1 r3 r3 2 r2 r2 3 S! acc S4 4 r1 r1 \u56e0\u4e3a\u6ca1\u6709\u91cd\u590d\u7684\u51b2\u7a81\u9879\uff0c\u6545\u8be5\u6587\u6cd5\u4e3aSLR\uff081\uff09\u7684\u3002","title":"6"},{"location":"Compiler-Principle/4_%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%BD%9C%E4%B8%9A%282%29/#1","text":"\u89c4\u8303LR\u9879\u96c6\u65cf I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> a\u00b7 , $], [S' -> a\u00b7 , a] I2: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +] I4: [S' -> SS\u00b7+, $], [S' -> SS\u00b7+, a] [S' -> SS\u00b7*, $], [S' -> SS\u00b7*, a] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I5: [S' -> SS+\u00b7, $], [S' -> SS+\u00b7, a] I6: [S' -> SS*\u00b7, $], [S' -> SS*\u00b7, a] I7: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, +] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I8: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +] I9: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +] LALR\u9879\u96c6\u65cf: I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I2: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +], [S' -> SS\u00b7+, $] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, $] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +], [S' -> a\u00b7 , $] I4: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +], [S' -> SS+\u00b7, $] I5: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +], [S' -> SS*\u00b7, $]","title":"1"},{"location":"Compiler-Principle/5/","text":"\u7f16\u8bd1\u539f\u7406 \u7b2c\u4e94\u6b21\u4f5c\u4e1a \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 18805156360@163.com 4.7.1 \u00b6 \u89c4\u8303LR\u9879\u96c6\u65cf I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> a\u00b7 , $], [S' -> a\u00b7 , a] I2: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +] I4: [S' -> SS\u00b7+, $], [S' -> SS\u00b7+, a] [S' -> SS\u00b7*, $], [S' -> SS\u00b7*, a] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I5: [S' -> SS+\u00b7, $], [S' -> SS+\u00b7, a] I6: [S' -> SS*\u00b7, $], [S' -> SS*\u00b7, a] I7: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, +] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I8: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +] I9: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +] LALR\u9879\u96c6\u65cf: I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I2: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +], [S' -> SS\u00b7+, $] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, $] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +], [S' -> a\u00b7 , $] I4: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +], [S' -> SS+\u00b7, $] I5: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +], [S' -> SS*\u00b7, $] 5.1.2 \u00b6 \u4ea7\u751f\u5f0f \u8bed\u6cd5\u89c4\u5219 \\(L -> En\\) \\(L.val = E.val\\) \\(E -> TE'\\) \\(E'.inh = T.val\\) \\(E.val = E'.syn\\) \\(E' -> +TE_1'\\) \\(E_1'.inh = E'.inh + T.val\\) \\(E'.syn = E_1'.syn\\) \\(E' -> \\epsilon\\) \\(E'.syn = E'.inh\\) \\(T -> FT'\\) \\(T'.inh = F.val\\) \\(T.val = T'.syn\\) \\(T' -> *FT_1'\\) \\(T_1'.inh = T'.inh * F.val,\\) \\(T'.syn = T_1'.syn\\) \\(T' -> \\epsilon\\) \\(T'.syn = T'.inh\\) \\(F -> (E)\\) \\(F.val = E.val\\) \\(F -> digit\\) \\(F.val = digit.lexval\\) 5.2.2 \u00b6","title":"\u4f5c\u4e1a5"},{"location":"Compiler-Principle/5/#_1","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 18805156360@163.com","title":"\u7f16\u8bd1\u539f\u7406 \u7b2c\u4e94\u6b21\u4f5c\u4e1a"},{"location":"Compiler-Principle/5/#471","text":"\u89c4\u8303LR\u9879\u96c6\u65cf I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> a\u00b7 , $], [S' -> a\u00b7 , a] I2: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +] I4: [S' -> SS\u00b7+, $], [S' -> SS\u00b7+, a] [S' -> SS\u00b7*, $], [S' -> SS\u00b7*, a] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I5: [S' -> SS+\u00b7, $], [S' -> SS+\u00b7, a] I6: [S' -> SS*\u00b7, $], [S' -> SS*\u00b7, a] I7: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, +] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I8: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +] I9: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +] LALR\u9879\u96c6\u65cf: I0: [S' -> \u00b7S , $] [S' -> \u00b7SS+, $], [S' -> \u00b7SS+, a] [S' -> \u00b7SS*, $], [S' -> \u00b7SS*, a] [S' -> \u00b7a , $], [S' -> \u00b7a , a] I1: [S' -> S\u00b7 , $] [S' -> S\u00b7S+, $], [S' -> S\u00b7S+, a] [S' -> S\u00b7S*, $], [S' -> S\u00b7S*, a] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I2: [S' -> SS\u00b7+, a], [S' -> SS\u00b7+, *], [S' -> SS\u00b7+, +], [S' -> SS\u00b7+, $] [S' -> SS\u00b7*, a], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, *], [S' -> SS\u00b7*, $] [S' -> S\u00b7S+, a], [S' -> S\u00b7S+, *], [S' -> S\u00b7S+, +] [S' -> S\u00b7S*, a], [S' -> S\u00b7S*, *], [S' -> S\u00b7S*, +] [S' -> \u00b7SS+, a], [S' -> \u00b7SS+, *], [S' -> \u00b7SS+, +] [S' -> \u00b7SS*, a], [S' -> \u00b7SS*, *], [S' -> \u00b7SS*, +] [S' -> \u00b7a , a], [S' -> \u00b7a , *], [S' -> \u00b7a , +] I3: [S' -> a\u00b7 , a], [S' -> a\u00b7 , *], [S' -> a\u00b7 , +], [S' -> a\u00b7 , $] I4: [S' -> SS+\u00b7, a], [S' -> SS+\u00b7, *], [S' -> SS+\u00b7, +], [S' -> SS+\u00b7, $] I5: [S' -> SS*\u00b7, a], [S' -> SS*\u00b7, *], [S' -> SS*\u00b7, +], [S' -> SS*\u00b7, $]","title":"4.7.1"},{"location":"Compiler-Principle/5/#512","text":"\u4ea7\u751f\u5f0f \u8bed\u6cd5\u89c4\u5219 \\(L -> En\\) \\(L.val = E.val\\) \\(E -> TE'\\) \\(E'.inh = T.val\\) \\(E.val = E'.syn\\) \\(E' -> +TE_1'\\) \\(E_1'.inh = E'.inh + T.val\\) \\(E'.syn = E_1'.syn\\) \\(E' -> \\epsilon\\) \\(E'.syn = E'.inh\\) \\(T -> FT'\\) \\(T'.inh = F.val\\) \\(T.val = T'.syn\\) \\(T' -> *FT_1'\\) \\(T_1'.inh = T'.inh * F.val,\\) \\(T'.syn = T_1'.syn\\) \\(T' -> \\epsilon\\) \\(T'.syn = T'.inh\\) \\(F -> (E)\\) \\(F.val = E.val\\) \\(F -> digit\\) \\(F.val = digit.lexval\\)","title":"5.1.2"},{"location":"Compiler-Principle/5/#522","text":"","title":"5.2.2"},{"location":"Compiler-Principle/6/","text":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a\u516d \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 18805156360 5.4.3 \u00b6 \u5148\u63d0\u53d6\u5de6\u516c\u56e0\u5b50 \\(B \\rightarrow B_1 d~|~1\\) \\(d \\rightarrow 0~|~1\\) \u6d88\u9664\u5de6\u9012\u5f52\u540e\u5f97 \\(B \\rightarrow 1~\\{R.i = 1\\}~R~\\{B.val=R.val\\}\\) \\(R \\rightarrow d~\\{R_1.i = 2*R.i+d.val\\}~R_1~\\{R.val=R_1.val\\}\\) \\(R \\rightarrow ~\\epsilon~\\{R.val=R.i\\}\\) \\(d \\rightarrow 0~\\{d.val=0\\}\\) \\(d \\rightarrow 1~\\{d.val=1\\}\\)","title":"\u4f5c\u4e1a6"},{"location":"Compiler-Principle/6/#_1","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf 18805156360","title":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a\u516d"},{"location":"Compiler-Principle/6/#543","text":"\u5148\u63d0\u53d6\u5de6\u516c\u56e0\u5b50 \\(B \\rightarrow B_1 d~|~1\\) \\(d \\rightarrow 0~|~1\\) \u6d88\u9664\u5de6\u9012\u5f52\u540e\u5f97 \\(B \\rightarrow 1~\\{R.i = 1\\}~R~\\{B.val=R.val\\}\\) \\(R \\rightarrow d~\\{R_1.i = 2*R.i+d.val\\}~R_1~\\{R.val=R_1.val\\}\\) \\(R \\rightarrow ~\\epsilon~\\{R.val=R.i\\}\\) \\(d \\rightarrow 0~\\{d.val=0\\}\\) \\(d \\rightarrow 1~\\{d.val=1\\}\\)","title":"5.4.3"},{"location":"Compiler-Principle/7/","text":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a7 \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf nju_wzy@163.com 6.1.2 \u00b6 6.2.2 \u00b6 a = b[i] + c[j] \u56db\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) \\(result\\) 0 * \\(i\\) 8 \\(t_1\\) 1 =[] \\(b\\) \\(t_1\\) \\(t_2\\) 2 * \\(j\\) 8 \\(t_3\\) 3 =[] \\(c\\) \\(t_3\\) \\(t_4\\) 4 + \\(t_3\\) \\(t_4\\) \\(t_5\\) 5 = \\(t_5\\) \\(a\\) \u200b \u200b \u4e09\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) 0 * \\(i\\) 8 1 =[] \\(b\\) (0) 2 * \\(j\\) 8 3 =[] \\(c\\) (2) 4 + (1) (3) 5 = \\(a\\) (4) a[i] = b*c - b*d \u56db\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) \\(result\\) 0 * \\(b\\) \\(c\\) \\(t_!\\) 1 * \\(b\\) \\(d\\) \\(t_2\\) 2 - \\(t_1\\) \\(t_2\\) \\(t_3\\) 3 * \\(i\\) 8 \\(t_4\\) 4 []= \\(t_4\\) \\(t_3\\) \\(a\\) \u4e09\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) 0 * \\(b\\) \\(c\\) 1 * \\(b\\) \\(d\\) 2 - (0) (1) 3 * \\(i\\) 8 4 + \\(a\\) (3) 5 *= (4) (2) \u200b","title":"\u4f5c\u4e1a7"},{"location":"Compiler-Principle/7/#7","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf nju_wzy@163.com","title":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a7"},{"location":"Compiler-Principle/7/#612","text":"","title":"6.1.2"},{"location":"Compiler-Principle/7/#622","text":"a = b[i] + c[j] \u56db\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) \\(result\\) 0 * \\(i\\) 8 \\(t_1\\) 1 =[] \\(b\\) \\(t_1\\) \\(t_2\\) 2 * \\(j\\) 8 \\(t_3\\) 3 =[] \\(c\\) \\(t_3\\) \\(t_4\\) 4 + \\(t_3\\) \\(t_4\\) \\(t_5\\) 5 = \\(t_5\\) \\(a\\) \u200b \u200b \u4e09\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) 0 * \\(i\\) 8 1 =[] \\(b\\) (0) 2 * \\(j\\) 8 3 =[] \\(c\\) (2) 4 + (1) (3) 5 = \\(a\\) (4) a[i] = b*c - b*d \u56db\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) \\(result\\) 0 * \\(b\\) \\(c\\) \\(t_!\\) 1 * \\(b\\) \\(d\\) \\(t_2\\) 2 - \\(t_1\\) \\(t_2\\) \\(t_3\\) 3 * \\(i\\) 8 \\(t_4\\) 4 []= \\(t_4\\) \\(t_3\\) \\(a\\) \u4e09\u5143\u5f0f\u5e8f\u5217 \\(op\\) \\(arg_1\\) \\(arg_2\\) 0 * \\(b\\) \\(c\\) 1 * \\(b\\) \\(d\\) 2 - (0) (1) 3 * \\(i\\) 8 4 + \\(a\\) (3) 5 *= (4) (2) \u200b","title":"6.2.2"},{"location":"Compiler-Principle/8/","text":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a8 \u00b6 151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf nju_wzy@163.com 6.4.3 \u00b6 \u4e2d\u95f4\u4ee3\u7801: t1 = i * 16 t2 = j * 4 t3 = t1 + t2 t4 = b[t3] t5 = t4 * 12 t6 = k * 4 t7 = c[t6] t8 = t7 * 4 t9 = t5 + t8 t10 = a[t9] x = t10 6.4.8 \u00b6 A[3,4,5] = [(3-1)*5*6 + (4-0)*6 +(5-5)] = 672 A[1,2,7] = [(1-1)*5*6 + (2-0)*6 +(7-5)] = 112 A[4,3,9] = [(4-1)*5*6 + (3-0)*6 +(9-5)] = 896 6.6.1 \u00b6 S -> for (S1; B; S2) S3 S1.next = newlabel() B.true = newlabel() B.false = S.next S2.next = S1.next S3.next = newlabel() S.code = S1.code || lable(S1.next) || B.code || lable(B.true) || S3.code || label(S3.next) || S2.code || gen('goto', S1.next)","title":"\u4f5c\u4e1a8"},{"location":"Compiler-Principle/8/#8","text":"151220129 \u8ba1\u79d1 \u5434\u653f\u4ebf nju_wzy@163.com","title":"\u7f16\u8bd1\u539f\u7406 \u4f5c\u4e1a8"},{"location":"Compiler-Principle/8/#643","text":"\u4e2d\u95f4\u4ee3\u7801: t1 = i * 16 t2 = j * 4 t3 = t1 + t2 t4 = b[t3] t5 = t4 * 12 t6 = k * 4 t7 = c[t6] t8 = t7 * 4 t9 = t5 + t8 t10 = a[t9] x = t10","title":"6.4.3"},{"location":"Compiler-Principle/8/#648","text":"A[3,4,5] = [(3-1)*5*6 + (4-0)*6 +(5-5)] = 672 A[1,2,7] = [(1-1)*5*6 + (2-0)*6 +(7-5)] = 112 A[4,3,9] = [(4-1)*5*6 + (3-0)*6 +(9-5)] = 896","title":"6.4.8"},{"location":"Compiler-Principle/8/#661","text":"S -> for (S1; B; S2) S3 S1.next = newlabel() B.true = newlabel() B.false = S.next S2.next = S1.next S3.next = newlabel() S.code = S1.code || lable(S1.next) || B.code || lable(B.true) || S3.code || label(S3.next) || S2.code || gen('goto', S1.next)","title":"6.6.1"},{"location":"Compiler-Principle/9/","text":"\u4f5c\u4e1a9 \u00b6","title":"\u4f5c\u4e1a9"},{"location":"Compiler-Principle/9/#9","text":"","title":"\u4f5c\u4e1a9"}]}